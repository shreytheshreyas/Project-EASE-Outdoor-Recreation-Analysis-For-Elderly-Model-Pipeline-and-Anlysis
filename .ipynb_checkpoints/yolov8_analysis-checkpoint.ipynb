{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66615ec5-1038-4179-ae48-c404cde2585a",
   "metadata": {},
   "source": [
    "#### Importing Necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc6b523-1f31-4096-88ab-6abac52f3e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c5fcc-4a81-49ca-8326-ce58f5b36972",
   "metadata": {},
   "source": [
    "#### Pulling necessary directories and from boxmot repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737f71c9-064b-4a9e-818b-97542554083d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolo_tracking' already exists and is not an empty directory.\n",
      "/Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking\n",
      "Using pip 23.3 from /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages/pip (python 3.11)\n",
      "Obtaining file:///Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking\n",
      "  Running command python setup.py egg_info\n",
      "  /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/setup.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "    import pkg_resources as pkg\n",
      "  running egg_info\n",
      "  creating /private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-xx0gtxwu/boxmot.egg-info\n",
      "  writing /private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-xx0gtxwu/boxmot.egg-info/PKG-INFO\n",
      "  writing dependency_links to /private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-xx0gtxwu/boxmot.egg-info/dependency_links.txt\n",
      "  writing requirements to /private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-xx0gtxwu/boxmot.egg-info/requires.txt\n",
      "  writing top-level names to /private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-xx0gtxwu/boxmot.egg-info/top_level.txt\n",
      "  writing manifest file '/private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-xx0gtxwu/boxmot.egg-info/SOURCES.txt'\n",
      "  reading manifest file '/private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-xx0gtxwu/boxmot.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*' found under directory '__pycache__'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file '/private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-xx0gtxwu/boxmot.egg-info/SOURCES.txt'\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filterpy>=1.4.5 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (1.4.5)\n",
      "Requirement already satisfied: ftfy>=6.1.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (6.1.1)\n",
      "Requirement already satisfied: gdown>=4.7.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (4.7.1)\n",
      "Requirement already satisfied: GitPython>=3.1.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (3.1.40)\n",
      "Requirement already satisfied: lapx>=0.5.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (0.5.5)\n",
      "Requirement already satisfied: loguru>=0.7.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (0.7.2)\n",
      "Requirement already satisfied: numpy==1.24.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (1.24.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (4.7.0.72)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (1.5.1)\n",
      "Requirement already satisfied: pre-commit>=3.3.3 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (3.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (6.0.1)\n",
      "Requirement already satisfied: regex>=2023.6.3 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (2023.10.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (1.3.2)\n",
      "Requirement already satisfied: tensorboard>=2.13.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (2.15.0)\n",
      "Requirement already satisfied: torch>=1.7.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (2.1.0)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (0.16.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (0.1.8)\n",
      "Requirement already satisfied: scipy in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from filterpy>=1.4.5->boxmot==10.0.43) (1.11.3)\n",
      "Requirement already satisfied: matplotlib in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from filterpy>=1.4.5->boxmot==10.0.43) (3.8.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from ftfy>=6.1.1->boxmot==10.0.43) (0.2.9)\n",
      "Requirement already satisfied: filelock in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot==10.0.43) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot==10.0.43) (2.31.0)\n",
      "Requirement already satisfied: six in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot==10.0.43) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot==10.0.43) (4.66.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot==10.0.43) (4.12.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from GitPython>=3.1.0->boxmot==10.0.43) (4.0.11)\n",
      "Requirement already satisfied: Cython>=0.29.32 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from lapx>=0.5.4->boxmot==10.0.43) (3.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pandas>=1.1.4->boxmot==10.0.43) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pandas>=1.1.4->boxmot==10.0.43) (2023.3.post1)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pre-commit>=3.3.3->boxmot==10.0.43) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pre-commit>=3.3.3->boxmot==10.0.43) (2.5.31)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pre-commit>=3.3.3->boxmot==10.0.43) (1.8.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pre-commit>=3.3.3->boxmot==10.0.43) (20.24.6)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from scikit-learn>=1.3.0->boxmot==10.0.43) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from scikit-learn>=1.3.0->boxmot==10.0.43) (3.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (1.59.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (3.5.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (4.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (68.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot==10.0.43) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot==10.0.43) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot==10.0.43) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot==10.0.43) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot==10.0.43) (2023.10.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torchvision>=0.8.1->boxmot==10.0.43) (10.1.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.0->boxmot==10.0.43) (5.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.13.0->boxmot==10.0.43) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.13.0->boxmot==10.0.43) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.13.0->boxmot==10.0.43) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.13.0->boxmot==10.0.43) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot==10.0.43) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot==10.0.43) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot==10.0.43) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot==10.0.43) (2023.7.22)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->boxmot==10.0.43) (0.3.7)\n",
      "Requirement already satisfied: platformdirs<4,>=3.9.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->boxmot==10.0.43) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard>=2.13.0->boxmot==10.0.43) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from beautifulsoup4->gdown>=4.7.1->boxmot==10.0.43) (2.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot==10.0.43) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot==10.0.43) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot==10.0.43) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot==10.0.43) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot==10.0.43) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot==10.0.43) (3.1.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot==10.0.43) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from sympy->torch>=1.7.0->boxmot==10.0.43) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.13.0->boxmot==10.0.43) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.13.0->boxmot==10.0.43) (3.2.2)\n",
      "Installing collected packages: boxmot\n",
      "  Attempting uninstall: boxmot\n",
      "    Found existing installation: boxmot 10.0.46\n",
      "    Uninstalling boxmot-10.0.46:\n",
      "      Removing file or directory /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages/boxmot.egg-link\n",
      "      Removing pth entries from /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages/easy-install.pth:\n",
      "      Removing entry: /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/yolo_tracking\n",
      "      Successfully uninstalled boxmot-10.0.46\n",
      "  Running setup.py develop for boxmot\n",
      "    Running command python setup.py develop\n",
      "    /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/setup.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "      import pkg_resources as pkg\n",
      "    running develop\n",
      "    /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
      "    !!\n",
      "\n",
      "            ********************************************************************************\n",
      "            Please avoid running ``setup.py`` and ``easy_install``.\n",
      "            Instead, use pypa/build, pypa/installer or other\n",
      "            standards-based tools.\n",
      "\n",
      "            See https://github.com/pypa/setuptools/issues/917 for details.\n",
      "            ********************************************************************************\n",
      "\n",
      "    !!\n",
      "      easy_install.initialize_options(self)\n",
      "    /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "    !!\n",
      "\n",
      "            ********************************************************************************\n",
      "            Please avoid running ``setup.py`` directly.\n",
      "            Instead, use pypa/build, pypa/installer or other\n",
      "            standards-based tools.\n",
      "\n",
      "            See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "            ********************************************************************************\n",
      "\n",
      "    !!\n",
      "      self.initialize_options()\n",
      "    running egg_info\n",
      "    writing boxmot.egg-info/PKG-INFO\n",
      "    writing dependency_links to boxmot.egg-info/dependency_links.txt\n",
      "    writing requirements to boxmot.egg-info/requires.txt\n",
      "    writing top-level names to boxmot.egg-info/top_level.txt\n",
      "    reading manifest file 'boxmot.egg-info/SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    warning: no previously-included files matching '*' found under directory '__pycache__'\n",
      "    adding license file 'LICENSE'\n",
      "    writing manifest file 'boxmot.egg-info/SOURCES.txt'\n",
      "    running build_ext\n",
      "    Creating /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages/boxmot.egg-link (link to .)\n",
      "    Adding boxmot 10.0.43 to easy-install.pth file\n",
      "\n",
      "    Installed /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking\n",
      "Successfully installed boxmot-10.0.43\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/mikel-brostrom/yolo_tracking.git\n",
    "%cd yolo_tracking\n",
    "!pip install -v -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4208a5cf-a0bd-4c92-888c-c40382a46788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4709e8-c377-4ddd-aaf4-74c890bfff37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking\n",
      "Using pip 23.3 from /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages/pip (python 3.11)\n",
      "Obtaining file:///Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking\n",
      "  Running command python setup.py egg_info\n",
      "  /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/setup.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "    import pkg_resources as pkg\n",
      "  running egg_info\n",
      "  creating /private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-0wd5hsvv/boxmot.egg-info\n",
      "  writing /private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-0wd5hsvv/boxmot.egg-info/PKG-INFO\n",
      "  writing dependency_links to /private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-0wd5hsvv/boxmot.egg-info/dependency_links.txt\n",
      "  writing requirements to /private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-0wd5hsvv/boxmot.egg-info/requires.txt\n",
      "  writing top-level names to /private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-0wd5hsvv/boxmot.egg-info/top_level.txt\n",
      "  writing manifest file '/private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-0wd5hsvv/boxmot.egg-info/SOURCES.txt'\n",
      "  reading manifest file '/private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-0wd5hsvv/boxmot.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*' found under directory '__pycache__'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file '/private/var/folders/2x/68c6g8fs0kb5_l3hvkrcbpb80000gn/T/pip-pip-egg-info-0wd5hsvv/boxmot.egg-info/SOURCES.txt'\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filterpy>=1.4.5 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (1.4.5)\n",
      "Requirement already satisfied: ftfy>=6.1.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (6.1.1)\n",
      "Requirement already satisfied: gdown>=4.7.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (4.7.1)\n",
      "Requirement already satisfied: GitPython>=3.1.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (3.1.40)\n",
      "Requirement already satisfied: lapx>=0.5.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (0.5.5)\n",
      "Requirement already satisfied: loguru>=0.7.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (0.7.2)\n",
      "Requirement already satisfied: numpy==1.24.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (1.24.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (4.7.0.72)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (1.5.1)\n",
      "Requirement already satisfied: pre-commit>=3.3.3 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (3.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (6.0.1)\n",
      "Requirement already satisfied: regex>=2023.6.3 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (2023.10.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (1.3.2)\n",
      "Requirement already satisfied: tensorboard>=2.13.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (2.15.0)\n",
      "Requirement already satisfied: torch>=1.7.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (2.1.0)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (0.16.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot==10.0.43) (0.1.8)\n",
      "Requirement already satisfied: scipy in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from filterpy>=1.4.5->boxmot==10.0.43) (1.11.3)\n",
      "Requirement already satisfied: matplotlib in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from filterpy>=1.4.5->boxmot==10.0.43) (3.8.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from ftfy>=6.1.1->boxmot==10.0.43) (0.2.9)\n",
      "Requirement already satisfied: filelock in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot==10.0.43) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot==10.0.43) (2.31.0)\n",
      "Requirement already satisfied: six in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot==10.0.43) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot==10.0.43) (4.66.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot==10.0.43) (4.12.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from GitPython>=3.1.0->boxmot==10.0.43) (4.0.11)\n",
      "Requirement already satisfied: Cython>=0.29.32 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from lapx>=0.5.4->boxmot==10.0.43) (3.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pandas>=1.1.4->boxmot==10.0.43) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pandas>=1.1.4->boxmot==10.0.43) (2023.3.post1)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pre-commit>=3.3.3->boxmot==10.0.43) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pre-commit>=3.3.3->boxmot==10.0.43) (2.5.31)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pre-commit>=3.3.3->boxmot==10.0.43) (1.8.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pre-commit>=3.3.3->boxmot==10.0.43) (20.24.6)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from scikit-learn>=1.3.0->boxmot==10.0.43) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from scikit-learn>=1.3.0->boxmot==10.0.43) (3.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (1.59.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (3.5.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (4.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (68.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot==10.0.43) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot==10.0.43) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot==10.0.43) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot==10.0.43) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot==10.0.43) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot==10.0.43) (2023.10.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torchvision>=0.8.1->boxmot==10.0.43) (10.1.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.0->boxmot==10.0.43) (5.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.13.0->boxmot==10.0.43) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.13.0->boxmot==10.0.43) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.13.0->boxmot==10.0.43) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.13.0->boxmot==10.0.43) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot==10.0.43) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot==10.0.43) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot==10.0.43) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot==10.0.43) (2023.7.22)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->boxmot==10.0.43) (0.3.7)\n",
      "Requirement already satisfied: platformdirs<4,>=3.9.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->boxmot==10.0.43) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard>=2.13.0->boxmot==10.0.43) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from beautifulsoup4->gdown>=4.7.1->boxmot==10.0.43) (2.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot==10.0.43) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot==10.0.43) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot==10.0.43) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot==10.0.43) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot==10.0.43) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot==10.0.43) (3.1.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot==10.0.43) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from sympy->torch>=1.7.0->boxmot==10.0.43) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.13.0->boxmot==10.0.43) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.13.0->boxmot==10.0.43) (3.2.2)\n",
      "Installing collected packages: boxmot\n",
      "  Attempting uninstall: boxmot\n",
      "    Found existing installation: boxmot 10.0.43\n",
      "    Uninstalling boxmot-10.0.43:\n",
      "      Removing file or directory /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages/boxmot.egg-link\n",
      "      Removing pth entries from /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages/easy-install.pth:\n",
      "      Removing entry: /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking\n",
      "      Successfully uninstalled boxmot-10.0.43\n",
      "  Running setup.py develop for boxmot\n",
      "    Running command python setup.py develop\n",
      "    /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/setup.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "      import pkg_resources as pkg\n",
      "    running develop\n",
      "    /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
      "    !!\n",
      "\n",
      "            ********************************************************************************\n",
      "            Please avoid running ``setup.py`` and ``easy_install``.\n",
      "            Instead, use pypa/build, pypa/installer or other\n",
      "            standards-based tools.\n",
      "\n",
      "            See https://github.com/pypa/setuptools/issues/917 for details.\n",
      "            ********************************************************************************\n",
      "\n",
      "    !!\n",
      "      easy_install.initialize_options(self)\n",
      "    /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "    !!\n",
      "\n",
      "            ********************************************************************************\n",
      "            Please avoid running ``setup.py`` directly.\n",
      "            Instead, use pypa/build, pypa/installer or other\n",
      "            standards-based tools.\n",
      "\n",
      "            See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "            ********************************************************************************\n",
      "\n",
      "    !!\n",
      "      self.initialize_options()\n",
      "    running egg_info\n",
      "    writing boxmot.egg-info/PKG-INFO\n",
      "    writing dependency_links to boxmot.egg-info/dependency_links.txt\n",
      "    writing requirements to boxmot.egg-info/requires.txt\n",
      "    writing top-level names to boxmot.egg-info/top_level.txt\n",
      "    reading manifest file 'boxmot.egg-info/SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    warning: no previously-included files matching '*' found under directory '__pycache__'\n",
      "    adding license file 'LICENSE'\n",
      "    writing manifest file 'boxmot.egg-info/SOURCES.txt'\n",
      "    running build_ext\n",
      "    Creating /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages/boxmot.egg-link (link to .)\n",
      "    Adding boxmot 10.0.43 to easy-install.pth file\n",
      "\n",
      "    Installed /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking\n",
      "Successfully installed boxmot-10.0.43\n"
     ]
    }
   ],
   "source": [
    "%cd yolo_tracking \n",
    "!pip install -v -e .\n",
    "#!conda install python=3.11 -y -y\n",
    "#!conda install -c pytorch pytorch -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3809177-5b42-4067-9990-4a23ba2f2ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boxmot in /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking (10.0.43)\n",
      "Requirement already satisfied: filterpy>=1.4.5 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (1.4.5)\n",
      "Requirement already satisfied: ftfy>=6.1.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (6.1.1)\n",
      "Requirement already satisfied: gdown>=4.7.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (4.7.1)\n",
      "Requirement already satisfied: GitPython>=3.1.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (3.1.40)\n",
      "Requirement already satisfied: lapx>=0.5.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (0.5.5)\n",
      "Requirement already satisfied: loguru>=0.7.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (0.7.2)\n",
      "Requirement already satisfied: numpy==1.24.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (1.24.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (4.7.0.72)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (1.5.1)\n",
      "Requirement already satisfied: pre-commit>=3.3.3 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (3.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (6.0.1)\n",
      "Requirement already satisfied: regex>=2023.6.3 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (2023.10.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (1.3.2)\n",
      "Requirement already satisfied: tensorboard>=2.13.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (2.15.0)\n",
      "Requirement already satisfied: torch>=1.7.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (2.1.0)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (0.16.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from boxmot) (0.1.8)\n",
      "Requirement already satisfied: scipy in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from filterpy>=1.4.5->boxmot) (1.11.3)\n",
      "Requirement already satisfied: matplotlib in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from filterpy>=1.4.5->boxmot) (3.8.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from ftfy>=6.1.1->boxmot) (0.2.9)\n",
      "Requirement already satisfied: filelock in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot) (2.31.0)\n",
      "Requirement already satisfied: six in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot) (4.66.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gdown>=4.7.1->boxmot) (4.12.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from GitPython>=3.1.0->boxmot) (4.0.11)\n",
      "Requirement already satisfied: Cython>=0.29.32 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from lapx>=0.5.4->boxmot) (3.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pandas>=1.1.4->boxmot) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pandas>=1.1.4->boxmot) (2023.3.post1)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pre-commit>=3.3.3->boxmot) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pre-commit>=3.3.3->boxmot) (2.5.31)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pre-commit>=3.3.3->boxmot) (1.8.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pre-commit>=3.3.3->boxmot) (20.24.6)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from scikit-learn>=1.3.0->boxmot) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from scikit-learn>=1.3.0->boxmot) (3.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot) (1.59.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot) (3.5.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot) (4.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot) (68.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from tensorboard>=2.13.0->boxmot) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torch>=1.7.0->boxmot) (2023.10.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from torchvision>=0.8.1->boxmot) (10.1.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.0->boxmot) (5.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.13.0->boxmot) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.13.0->boxmot) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.13.0->boxmot) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.13.0->boxmot) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot) (2023.7.22)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->boxmot) (0.3.7)\n",
      "Requirement already satisfied: platformdirs<4,>=3.9.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->boxmot) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard>=2.13.0->boxmot) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from beautifulsoup4->gdown>=4.7.1->boxmot) (2.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from matplotlib->filterpy>=1.4.5->boxmot) (3.1.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests[socks]->gdown>=4.7.1->boxmot) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from sympy->torch>=1.7.0->boxmot) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.13.0->boxmot) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/shreyaskumar/opt/anaconda3/envs/sutd_yolo_v8/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.13.0->boxmot) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install boxmot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95eb526-3a6d-446d-a756-7d0dbfa4015e",
   "metadata": {},
   "source": [
    "### Output format present in files = frame_id, object_id, bounding_box_left, bounding_box_top, bounding_box_width, bounding_box_height, x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c2dc481-a3a9-45d4-8769-4926d1c54ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING  'ultralytics.yolo.engine' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.engine' instead.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "The results object is \n",
      "<generator object BasePredictor.stream_inference at 0x1a22ef1c0>\n",
      "\n",
      "\u001b[32m2023-11-21 14:34:24.860\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m207\u001b[0m - \u001b[32m\u001b[1mSuccessfully loaded pretrained weights from \"/Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/examples/weights/osnet_x0_25_msmt17.pt\"\u001b[0m\n",
      "\u001b[32m2023-11-21 14:34:24.860\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m211\u001b[0m - \u001b[33m\u001b[1mThe following layers are discarded due to unmatched keys or layer size: ('classifier.weight', 'classifier.bias')\u001b[0m\n",
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Bounding Box Information for frame 0\n",
      "boxes_id = tensor([1.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6164], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[853.9891, 355.2742, 888.3380, 446.9482]], dtype=torch.float64)\n",
      "video 1/1 (1/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 191.0ms\n",
      "video 1/1 (2/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 103.0ms\n",
      "video 1/1 (3/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 97.3ms\n",
      "video 1/1 (4/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 86.3ms\n",
      "video 1/1 (5/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 79.8ms\n",
      "video 1/1 (6/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 120.2ms\n",
      "video 1/1 (7/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 95.2ms\n",
      "video 1/1 (8/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 93.6ms\n",
      "video 1/1 (9/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 78.9ms\n",
      "Bounding Box Information for frame 9\n",
      "boxes_id = tensor([2.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7111], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[784.6754, 355.2055, 816.2223, 430.2683]], dtype=torch.float64)\n",
      "video 1/1 (10/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 96.8ms\n",
      "video 1/1 (11/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 89.5ms\n",
      "video 1/1 (12/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 77.8ms\n",
      "video 1/1 (13/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 77.6ms\n",
      "video 1/1 (14/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 78.0ms\n",
      "video 1/1 (15/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 86.2ms\n",
      "video 1/1 (16/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 122.2ms\n",
      "video 1/1 (17/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 80.7ms\n",
      "video 1/1 (18/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.1ms\n",
      "video 1/1 (19/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 80.1ms\n",
      "video 1/1 (20/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 83.5ms\n",
      "video 1/1 (21/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 94.8ms\n",
      "video 1/1 (22/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 146.3ms\n",
      "video 1/1 (23/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 97.4ms\n",
      "video 1/1 (24/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 86.0ms\n",
      "video 1/1 (25/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 78.8ms\n",
      "video 1/1 (26/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 125.0ms\n",
      "video 1/1 (27/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 94.8ms\n",
      "video 1/1 (28/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 83.9ms\n",
      "video 1/1 (29/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 79.5ms\n",
      "video 1/1 (30/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.2ms\n",
      "Bounding Box Information for frame 30\n",
      "boxes_id = tensor([2.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5180], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[771.6590, 356.2791, 813.4616, 460.8589]], dtype=torch.float64)\n",
      "video 1/1 (31/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 109.4ms\n",
      "Bounding Box Information for frame 31\n",
      "boxes_id = tensor([2.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7344], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[784.4495, 353.5749, 831.0798, 457.2317]], dtype=torch.float64)\n",
      "video 1/1 (32/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 142.2ms\n",
      "Bounding Box Information for frame 32\n",
      "boxes_id = tensor([2.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5942], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[802.9199, 360.5661, 839.8294, 451.7137]], dtype=torch.float64)\n",
      "video 1/1 (33/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 112.1ms\n",
      "Bounding Box Information for frame 33\n",
      "boxes_id = tensor([2.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5125], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[809.3203, 353.5703, 847.9779, 444.2285]], dtype=torch.float64)\n",
      "video 1/1 (34/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 162.5ms\n",
      "video 1/1 (35/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 118.0ms\n",
      "video 1/1 (36/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 106.4ms\n",
      "Bounding Box Information for frame 36\n",
      "boxes_id = tensor([2.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5484], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[827.5379, 342.8517, 861.7779, 431.3354]], dtype=torch.float64)\n",
      "video 1/1 (37/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 99.1ms\n",
      "Bounding Box Information for frame 37\n",
      "boxes_id = tensor([2.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5166], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[830.2599, 341.0393, 865.8029, 427.3824]], dtype=torch.float64)\n",
      "video 1/1 (38/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 171.2ms\n",
      "Bounding Box Information for frame 38\n",
      "boxes_id = tensor([2.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5543], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[833.8978, 335.1174, 868.7747, 421.5998]], dtype=torch.float64)\n",
      "video 1/1 (39/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 110.2ms\n",
      "video 1/1 (40/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 150.9ms\n",
      "video 1/1 (41/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 139.2ms\n",
      "video 1/1 (42/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 91.7ms\n",
      "Bounding Box Information for frame 42\n",
      "boxes_id = tensor([2.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6376], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[855.3305, 329.1476, 888.7744, 409.2864]], dtype=torch.float64)\n",
      "video 1/1 (43/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 97.3ms\n",
      "Bounding Box Information for frame 43\n",
      "boxes_id = tensor([4.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7200], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[524.8270, 370.2365, 565.6711, 478.3312]], dtype=torch.float64)\n",
      "video 1/1 (44/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 149.4ms\n",
      "video 1/1 (45/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 117.1ms\n",
      "video 1/1 (46/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 144.9ms\n",
      "video 1/1 (47/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 116.0ms\n",
      "video 1/1 (48/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 95.9ms\n",
      "video 1/1 (49/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 103.8ms\n",
      "video 1/1 (50/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 109.2ms\n",
      "video 1/1 (51/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 124.5ms\n",
      "video 1/1 (52/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 97.9ms\n",
      "video 1/1 (53/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 82.1ms\n",
      "Bounding Box Information for frame 53\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6430], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[563.7891, 395.4330, 612.0571, 526.6430]], dtype=torch.float64)\n",
      "video 1/1 (54/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 74.8ms\n",
      "Bounding Box Information for frame 54\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6441], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[567.2015, 395.0163, 614.6964, 519.5871]], dtype=torch.float64)\n",
      "video 1/1 (55/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 133.3ms\n",
      "Bounding Box Information for frame 55\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6490], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[571.6520, 394.8061, 622.2704, 529.5500]], dtype=torch.float64)\n",
      "video 1/1 (56/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 155.6ms\n",
      "Bounding Box Information for frame 56\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6972], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[581.6968, 401.8763, 635.9543, 539.4476]], dtype=torch.float64)\n",
      "video 1/1 (57/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 66.0ms\n",
      "video 1/1 (58/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 70.3ms\n",
      "Bounding Box Information for frame 58\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6120], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[604.3749, 399.6161, 652.2021, 546.1116]], dtype=torch.float64)\n",
      "video 1/1 (59/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 73.9ms\n",
      "Bounding Box Information for frame 59\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5527], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[616.5408, 407.1118, 664.6235, 545.7887]], dtype=torch.float64)\n",
      "video 1/1 (60/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 80.4ms\n",
      "Bounding Box Information for frame 60\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6853], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[623.8973, 406.9330, 675.4155, 554.3762]], dtype=torch.float64)\n",
      "video 1/1 (61/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 79.2ms\n",
      "video 1/1 (62/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.7ms\n",
      "video 1/1 (63/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 87.5ms\n",
      "Bounding Box Information for frame 63\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7139], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[636.1707, 407.6686, 701.2557, 569.5851]], dtype=torch.float64)\n",
      "video 1/1 (64/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 74.2ms\n",
      "Bounding Box Information for frame 64\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5222], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[636.5679, 409.1949, 697.9772, 562.6508]], dtype=torch.float64)\n",
      "video 1/1 (65/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 91.8ms\n",
      "Bounding Box Information for frame 65\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7737], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[645.6224, 413.3361, 708.5164, 579.5764]], dtype=torch.float64)\n",
      "video 1/1 (66/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.4ms\n",
      "Bounding Box Information for frame 66\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6614], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[645.3372, 413.6261, 709.3422, 598.6992]], dtype=torch.float64)\n",
      "video 1/1 (67/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 73.5ms\n",
      "Bounding Box Information for frame 67\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7898], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[638.6447, 419.1047, 702.3548, 600.6083]], dtype=torch.float64)\n",
      "video 1/1 (68/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.1ms\n",
      "Bounding Box Information for frame 68\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7972], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[637.2280, 425.6238, 721.2202, 615.2231]], dtype=torch.float64)\n",
      "video 1/1 (69/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 76.3ms\n",
      "Bounding Box Information for frame 69\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7251], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[634.7052, 422.0148, 711.3867, 625.0148]], dtype=torch.float64)\n",
      "video 1/1 (70/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 77.2ms\n",
      "Bounding Box Information for frame 70\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7638], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[632.6369, 430.8880, 703.9061, 637.6996]], dtype=torch.float64)\n",
      "video 1/1 (71/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 70.1ms\n",
      "Bounding Box Information for frame 71\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8617], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[628.2344, 436.6825, 724.4667, 653.0063]], dtype=torch.float64)\n",
      "video 1/1 (72/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 73.0ms\n",
      "Bounding Box Information for frame 72\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8406], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[630.7106, 438.9926, 726.9832, 658.6717]], dtype=torch.float64)\n",
      "video 1/1 (73/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 70.6ms\n",
      "Bounding Box Information for frame 73\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7777], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[633.2950, 444.1524, 705.8785, 674.7441]], dtype=torch.float64)\n",
      "video 1/1 (74/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 77.4ms\n",
      "Bounding Box Information for frame 74\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8752], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[622.7467, 442.4680, 722.3485, 688.0441]], dtype=torch.float64)\n",
      "video 1/1 (75/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 71.3ms\n",
      "Bounding Box Information for frame 75\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8530], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[623.1875, 446.1300, 723.2142, 702.9039]], dtype=torch.float64)\n",
      "video 1/1 (76/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.3ms\n",
      "Bounding Box Information for frame 76\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8424], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[610.6756, 460.8452, 698.9385, 730.3785]], dtype=torch.float64)\n",
      "video 1/1 (77/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 69.9ms\n",
      "Bounding Box Information for frame 77\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8640], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[593.6968, 463.7990, 698.6358, 744.7231]], dtype=torch.float64)\n",
      "video 1/1 (78/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.8ms\n",
      "Bounding Box Information for frame 78\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8528], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[584.9660, 476.5624, 698.8716, 766.8618]], dtype=torch.float64)\n",
      "video 1/1 (79/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 73.4ms\n",
      "Bounding Box Information for frame 79\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8688], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[564.5977, 487.7616, 661.9956, 797.4870]], dtype=torch.float64)\n",
      "video 1/1 (80/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.9ms\n",
      "Bounding Box Information for frame 80\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8402], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[541.7401, 490.2577, 646.1430, 811.0245]], dtype=torch.float64)\n",
      "video 1/1 (81/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 74.4ms\n",
      "Bounding Box Information for frame 81\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8721], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[517.5370, 512.9625, 663.1871, 857.7951]], dtype=torch.float64)\n",
      "video 1/1 (82/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 76.6ms\n",
      "Bounding Box Information for frame 82\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8394], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[494.9171, 521.2161, 608.0750, 887.2636]], dtype=torch.float64)\n",
      "video 1/1 (83/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 76.5ms\n",
      "Bounding Box Information for frame 83\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8088], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[458.6945, 536.7283, 581.8303, 903.0304]], dtype=torch.float64)\n",
      "video 1/1 (84/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 82.5ms\n",
      "Bounding Box Information for frame 84\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8666], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[427.7530, 565.5760, 597.9416, 976.9437]], dtype=torch.float64)\n",
      "video 1/1 (85/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 77.0ms\n",
      "Bounding Box Information for frame 85\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8443], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 409.9426,  573.7397,  537.6327, 1015.3423]], dtype=torch.float64)\n",
      "video 1/1 (86/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.0ms\n",
      "Bounding Box Information for frame 86\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8548], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 370.2963,  600.2165,  511.0406, 1047.7507]], dtype=torch.float64)\n",
      "video 1/1 (87/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 77.9ms\n",
      "Bounding Box Information for frame 87\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8940], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 324.9272,  637.7175,  534.4691, 1077.3951]], dtype=torch.float64)\n",
      "video 1/1 (88/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 92.9ms\n",
      "Bounding Box Information for frame 88\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8490], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 287.5069,  652.7654,  457.0613, 1074.3461]], dtype=torch.float64)\n",
      "video 1/1 (89/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 85.8ms\n",
      "Bounding Box Information for frame 89\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8304], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 219.7370,  700.9578,  390.5157, 1080.0000]], dtype=torch.float64)\n",
      "video 1/1 (90/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 66.6ms\n",
      "Bounding Box Information for frame 90\n",
      "boxes_id = tensor([5.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8899], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 134.4893,  749.9145,  338.4351, 1080.0000]], dtype=torch.float64)\n",
      "video 1/1 (91/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 82.0ms\n",
      "video 1/1 (92/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 83.6ms\n",
      "video 1/1 (93/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 72.5ms\n",
      "video 1/1 (94/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 65.2ms\n",
      "video 1/1 (95/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 65.4ms\n",
      "video 1/1 (96/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 75.4ms\n",
      "video 1/1 (97/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 87.5ms\n",
      "video 1/1 (98/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 107.3ms\n",
      "video 1/1 (99/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 99.4ms\n",
      "video 1/1 (100/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 99.4ms\n",
      "video 1/1 (101/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 94.2ms\n",
      "video 1/1 (102/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 89.9ms\n",
      "video 1/1 (103/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 104.1ms\n",
      "video 1/1 (104/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 96.9ms\n",
      "video 1/1 (105/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 81.3ms\n",
      "video 1/1 (106/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 86.6ms\n",
      "video 1/1 (107/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 73.7ms\n",
      "video 1/1 (108/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 77.0ms\n",
      "video 1/1 (109/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 95.1ms\n",
      "video 1/1 (110/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.7ms\n",
      "video 1/1 (111/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 101.8ms\n",
      "video 1/1 (112/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 136.6ms\n",
      "video 1/1 (113/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 107.9ms\n",
      "video 1/1 (114/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 86.0ms\n",
      "video 1/1 (115/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 119.3ms\n",
      "video 1/1 (116/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 85.4ms\n",
      "video 1/1 (117/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 81.2ms\n",
      "video 1/1 (118/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 87.3ms\n",
      "video 1/1 (119/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 81.9ms\n",
      "video 1/1 (120/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 109.0ms\n",
      "video 1/1 (121/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 96.7ms\n",
      "video 1/1 (122/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 96.8ms\n",
      "video 1/1 (123/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 92.0ms\n",
      "video 1/1 (124/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 80.9ms\n",
      "video 1/1 (125/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 103.2ms\n",
      "video 1/1 (126/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 74.0ms\n",
      "video 1/1 (127/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 80.6ms\n",
      "video 1/1 (128/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 83.5ms\n",
      "video 1/1 (129/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 88.4ms\n",
      "video 1/1 (130/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 99.3ms\n",
      "video 1/1 (131/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.9ms\n",
      "video 1/1 (132/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 78.1ms\n",
      "video 1/1 (133/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 81.0ms\n",
      "video 1/1 (134/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 87.5ms\n",
      "video 1/1 (135/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 91.8ms\n",
      "video 1/1 (136/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 89.8ms\n",
      "video 1/1 (137/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 80.1ms\n",
      "video 1/1 (138/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 91.1ms\n",
      "Bounding Box Information for frame 138\n",
      "boxes_id = tensor([10.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6412], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[351.6122, 396.0948, 413.4006, 587.4662]], dtype=torch.float64)\n",
      "video 1/1 (139/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 91.9ms\n",
      "Bounding Box Information for frame 139\n",
      "boxes_id = tensor([10.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6907], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[383.7118, 416.1749, 449.1154, 579.0901]], dtype=torch.float64)\n",
      "video 1/1 (140/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 153.6ms\n",
      "video 1/1 (141/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 72.5ms\n",
      "video 1/1 (142/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 69.8ms\n",
      "video 1/1 (143/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.7ms\n",
      "Bounding Box Information for frame 143\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7600], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[497.2165, 392.8933, 548.6893, 544.9788]], dtype=torch.float64)\n",
      "video 1/1 (144/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 67.8ms\n",
      "Bounding Box Information for frame 144\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6678], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[522.9097, 399.6788, 572.4171, 541.2141]], dtype=torch.float64)\n",
      "video 1/1 (145/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 131.3ms\n",
      "Bounding Box Information for frame 145\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7289], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[543.6828, 397.8395, 601.0930, 533.8081]], dtype=torch.float64)\n",
      "video 1/1 (146/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 110.6ms\n",
      "Bounding Box Information for frame 146\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7393], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[565.4203, 387.5894, 610.4935, 526.4641]], dtype=torch.float64)\n",
      "video 1/1 (147/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 152.5ms\n",
      "Bounding Box Information for frame 147\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6516], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[583.8873, 387.4869, 636.5763, 520.5139]], dtype=torch.float64)\n",
      "video 1/1 (148/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 152.9ms\n",
      "Bounding Box Information for frame 148\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7579], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[605.3760, 389.0192, 647.4666, 514.2309]], dtype=torch.float64)\n",
      "video 1/1 (149/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.6ms\n",
      "Bounding Box Information for frame 149\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7218], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[621.2051, 387.2574, 660.9659, 508.9864]], dtype=torch.float64)\n",
      "video 1/1 (150/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 82.7ms\n",
      "Bounding Box Information for frame 150\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6503], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[633.1155, 380.6279, 679.0563, 504.1227]], dtype=torch.float64)\n",
      "video 1/1 (151/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 83.1ms\n",
      "Bounding Box Information for frame 151\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7000], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[656.1497, 375.9372, 693.1725, 499.2511]], dtype=torch.float64)\n",
      "video 1/1 (152/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 79.2ms\n",
      "Bounding Box Information for frame 152\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7756], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[664.7608, 372.6151, 706.3572, 494.0407]], dtype=torch.float64)\n",
      "video 1/1 (153/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 73.0ms\n",
      "Bounding Box Information for frame 153\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7038], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[679.5017, 375.9165, 724.4718, 488.4138]], dtype=torch.float64)\n",
      "video 1/1 (154/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.2ms\n",
      "video 1/1 (155/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 71.4ms\n",
      "Bounding Box Information for frame 155\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6928], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[713.1290, 372.4125, 749.8419, 479.2456]], dtype=torch.float64)\n",
      "video 1/1 (156/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 68.6ms\n",
      "Bounding Box Information for frame 156\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6375], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[720.6847, 362.6844, 762.7836, 475.2794]], dtype=torch.float64)\n",
      "video 1/1 (157/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 73.7ms\n",
      "Bounding Box Information for frame 157\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5955], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[739.6494, 357.9415, 776.2363, 469.9800]], dtype=torch.float64)\n",
      "video 1/1 (158/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.3ms\n",
      "video 1/1 (159/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 68.8ms\n",
      "Bounding Box Information for frame 159\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5782], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[756.5818, 358.3811, 796.1111, 461.3979]], dtype=torch.float64)\n",
      "video 1/1 (160/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 79.6ms\n",
      "Bounding Box Information for frame 160\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7146], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[772.7344, 350.1583, 804.8615, 458.3619]], dtype=torch.float64)\n",
      "video 1/1 (161/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 80.7ms\n",
      "Bounding Box Information for frame 161\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7061], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[777.0663, 351.9286, 811.2960, 458.9599]], dtype=torch.float64)\n",
      "video 1/1 (162/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.2ms\n",
      "Bounding Box Information for frame 162\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7382], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[781.4075, 353.7655, 817.7910, 455.4459]], dtype=torch.float64)\n",
      "video 1/1 (163/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 67.2ms\n",
      "Bounding Box Information for frame 163\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7912], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[790.9698, 351.0969, 824.7017, 447.7335]], dtype=torch.float64)\n",
      "video 1/1 (164/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 76.3ms\n",
      "Bounding Box Information for frame 164\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7179], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[797.8649, 352.6162, 833.2202, 446.9612]], dtype=torch.float64)\n",
      "video 1/1 (165/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.6ms\n",
      "Bounding Box Information for frame 165\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5361], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[804.2161, 350.7838, 839.5714, 442.6318]], dtype=torch.float64)\n",
      "video 1/1 (166/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 76.9ms\n",
      "video 1/1 (167/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 83.6ms\n",
      "video 1/1 (168/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 72.6ms\n",
      "video 1/1 (169/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 74.6ms\n",
      "video 1/1 (170/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 65.6ms\n",
      "Bounding Box Information for frame 170\n",
      "boxes_id = tensor([11.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7385], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[831.1831, 335.3589, 864.9022, 429.9944]], dtype=torch.float64)\n",
      "video 1/1 (171/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.2ms\n",
      "video 1/1 (172/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 75.3ms\n",
      "video 1/1 (173/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 76.8ms\n",
      "video 1/1 (174/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.8ms\n",
      "video 1/1 (175/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 88.2ms\n",
      "video 1/1 (176/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 157.4ms\n",
      "Bounding Box Information for frame 176\n",
      "boxes_id = tensor([12.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6080], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[879.8149, 335.6220, 908.1133, 415.2562]], dtype=torch.float64)\n",
      "video 1/1 (177/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 87.2ms\n",
      "Bounding Box Information for frame 177\n",
      "boxes_id = tensor([12.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6088], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[885.1040, 323.5565, 917.6177, 408.1937]], dtype=torch.float64)\n",
      "video 1/1 (178/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 107.1ms\n",
      "Bounding Box Information for frame 178\n",
      "boxes_id = tensor([12.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5372], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[889.1093, 320.7873, 920.3998, 408.2973]], dtype=torch.float64)\n",
      "video 1/1 (179/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.0ms\n",
      "video 1/1 (180/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 75.6ms\n",
      "Bounding Box Information for frame 180\n",
      "boxes_id = tensor([12.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5436], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[898.5256, 324.1219, 930.9340, 411.8881]], dtype=torch.float64)\n",
      "video 1/1 (181/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 78.9ms\n",
      "video 1/1 (182/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 75.7ms\n",
      "video 1/1 (183/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 69.0ms\n",
      "video 1/1 (184/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 71.2ms\n",
      "video 1/1 (185/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 77.4ms\n",
      "video 1/1 (186/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.9ms\n",
      "video 1/1 (187/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 147.2ms\n",
      "video 1/1 (188/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 99.4ms\n",
      "video 1/1 (189/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 81.0ms\n",
      "video 1/1 (190/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 114.9ms\n",
      "video 1/1 (191/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.1ms\n",
      "video 1/1 (192/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 127.9ms\n",
      "video 1/1 (193/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 89.8ms\n",
      "video 1/1 (194/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 109.5ms\n",
      "video 1/1 (195/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 119.4ms\n",
      "video 1/1 (196/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 82.1ms\n",
      "video 1/1 (197/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 95.7ms\n",
      "video 1/1 (198/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 88.6ms\n",
      "video 1/1 (199/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 101.9ms\n",
      "video 1/1 (200/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 120.5ms\n",
      "video 1/1 (201/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 86.3ms\n",
      "video 1/1 (202/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 89.4ms\n",
      "video 1/1 (203/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 89.3ms\n",
      "video 1/1 (204/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 101.6ms\n",
      "video 1/1 (205/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 94.0ms\n",
      "video 1/1 (206/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 86.2ms\n",
      "video 1/1 (207/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 85.9ms\n",
      "video 1/1 (208/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 88.2ms\n",
      "video 1/1 (209/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 79.9ms\n",
      "video 1/1 (210/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 87.8ms\n",
      "video 1/1 (211/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 80.9ms\n",
      "video 1/1 (212/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 87.8ms\n",
      "Bounding Box Information for frame 212\n",
      "boxes_id = tensor([13.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5456], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[802.8929, 363.5708, 843.2888, 441.9204]], dtype=torch.float64)\n",
      "video 1/1 (213/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 90.9ms\n",
      "Bounding Box Information for frame 213\n",
      "boxes_id = tensor([13.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7631], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[804.7231, 361.7682, 845.3183, 450.3444]], dtype=torch.float64)\n",
      "video 1/1 (214/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 161.8ms\n",
      "Bounding Box Information for frame 214\n",
      "boxes_id = tensor([13.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7131], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[801.1750, 364.6949, 843.5988, 459.5247]], dtype=torch.float64)\n",
      "video 1/1 (215/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 112.0ms\n",
      "Bounding Box Information for frame 215\n",
      "boxes_id = tensor([13.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6193], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[791.7759, 369.2526, 835.4198, 470.1523]], dtype=torch.float64)\n",
      "video 1/1 (216/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.4ms\n",
      "Bounding Box Information for frame 216\n",
      "boxes_id = tensor([13.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7347], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[782.7466, 376.0423, 827.6979, 484.4736]], dtype=torch.float64)\n",
      "video 1/1 (217/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 77.7ms\n",
      "Bounding Box Information for frame 217\n",
      "boxes_id = tensor([13.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7453], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[777.6709, 379.7287, 821.2668, 494.1457]], dtype=torch.float64)\n",
      "video 1/1 (218/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 73.7ms\n",
      "Bounding Box Information for frame 218\n",
      "boxes_id = tensor([13.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7543], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[769.6437, 384.3792, 818.8702, 506.3247]], dtype=torch.float64)\n",
      "video 1/1 (219/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.0ms\n",
      "Bounding Box Information for frame 219\n",
      "boxes_id = tensor([13.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7294], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[768.0208, 383.4274, 820.4479, 521.4551]], dtype=torch.float64)\n",
      "video 1/1 (220/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 76.5ms\n",
      "Bounding Box Information for frame 220\n",
      "boxes_id = tensor([13.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6469], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[769.8034, 387.2792, 823.9746, 535.4976]], dtype=torch.float64)\n",
      "video 1/1 (221/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 79.4ms\n",
      "Bounding Box Information for frame 221\n",
      "boxes_id = tensor([13.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5833], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[771.9183, 398.0189, 825.3988, 513.4913]], dtype=torch.float64)\n",
      "video 1/1 (222/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 74.2ms\n",
      "Bounding Box Information for frame 222\n",
      "boxes_id = tensor([13.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6182], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[756.0056, 405.4431, 823.0549, 560.5811]], dtype=torch.float64)\n",
      "video 1/1 (223/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 73.6ms\n",
      "Bounding Box Information for frame 223\n",
      "boxes_id = tensor([13.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6684], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[732.4397, 416.7339, 813.5481, 575.0312]], dtype=torch.float64)\n",
      "video 1/1 (224/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 69.7ms\n",
      "video 1/1 (225/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 1 motorcycle, 80.0ms\n",
      "video 1/1 (226/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 83.1ms\n",
      "video 1/1 (227/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 85.8ms\n",
      "video 1/1 (228/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 1 bicycle, 82.6ms\n",
      "Bounding Box Information for frame 228\n",
      "boxes_id = tensor([21.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7298], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[478.5301, 400.9216, 533.2496, 547.3528]], dtype=torch.float64)\n",
      "video 1/1 (229/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 90.1ms\n",
      "Bounding Box Information for frame 229\n",
      "boxes_id = tensor([21.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5558], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[490.3664, 404.4790, 542.2098, 540.4672]], dtype=torch.float64)\n",
      "video 1/1 (230/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 119.1ms\n",
      "video 1/1 (231/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 141.8ms\n",
      "video 1/1 (232/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 122.4ms\n",
      "Bounding Box Information for frame 232\n",
      "boxes_id = tensor([21.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5521], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[505.7997, 398.5472, 554.9006, 525.9465]], dtype=torch.float64)\n",
      "video 1/1 (233/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 88.4ms\n",
      "video 1/1 (234/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 132.2ms\n",
      "Bounding Box Information for frame 234\n",
      "boxes_id = tensor([21.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5520], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[497.9021, 394.3776, 553.7544, 519.5860]], dtype=torch.float64)\n",
      "video 1/1 (235/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 124.6ms\n",
      "Bounding Box Information for frame 235\n",
      "boxes_id = tensor([23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.9091], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1.9608e-01, 6.3577e+02, 1.6755e+02, 1.0800e+03]], dtype=torch.float64)\n",
      "video 1/1 (236/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 127.2ms\n",
      "Bounding Box Information for frame 236\n",
      "boxes_id = tensor([23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8845], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[  34.9186,  606.9156,  196.6057, 1041.9113]], dtype=torch.float64)\n",
      "video 1/1 (237/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 199.3ms\n",
      "video 1/1 (238/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 124.4ms\n",
      "Bounding Box Information for frame 238\n",
      "boxes_id = tensor([24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.9068], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[181.1342, 563.8514, 338.8579, 974.0437]], dtype=torch.float64)\n",
      "video 1/1 (239/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 109.6ms\n",
      "Bounding Box Information for frame 239\n",
      "boxes_id = tensor([24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8764], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[242.6371, 548.5765, 415.7670, 967.8981]], dtype=torch.float64)\n",
      "video 1/1 (240/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 73.2ms\n",
      "Bounding Box Information for frame 240\n",
      "boxes_id = tensor([24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6972], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[300.7008, 524.8441, 433.4240, 914.1012]], dtype=torch.float64)\n",
      "video 1/1 (241/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.4ms\n",
      "Bounding Box Information for frame 241\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8885, 0.7890], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[361.4295, 512.3489, 502.4453, 885.4789],\n",
      "        [  0.0000, 588.3140, 143.6045, 925.2773]], dtype=torch.float64)\n",
      "video 1/1 (242/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 72.8ms\n",
      "Bounding Box Information for frame 242\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8779, 0.7921], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[404.4923, 501.5467, 561.9776, 860.1468],\n",
      "        [ 33.6377, 568.8498, 156.0173, 889.5033]], dtype=torch.float64)\n",
      "video 1/1 (243/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 71.9ms\n",
      "Bounding Box Information for frame 243\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8580, 0.8121], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[445.4388, 492.3929, 573.5310, 814.7333],\n",
      "        [ 90.2651, 560.9834, 226.1445, 876.7496]], dtype=torch.float64)\n",
      "video 1/1 (244/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 88.8ms\n",
      "Bounding Box Information for frame 244\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8297, 0.7705], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[491.2047, 482.9648, 632.8331, 809.0912],\n",
      "        [135.5335, 543.2815, 258.9655, 842.9965]], dtype=torch.float64)\n",
      "video 1/1 (245/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 69.0ms\n",
      "Bounding Box Information for frame 245\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8464, 0.8357], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[532.9420, 465.3094, 666.6156, 777.6927],\n",
      "        [191.1408, 528.6843, 307.8725, 830.2198]], dtype=torch.float64)\n",
      "video 1/1 (246/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 72.2ms\n",
      "Bounding Box Information for frame 246\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8655, 0.8536], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[565.7581, 463.6096, 688.1756, 769.3483],\n",
      "        [233.4520, 519.6705, 353.7597, 808.6875]], dtype=torch.float64)\n",
      "video 1/1 (247/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 75.8ms\n",
      "Bounding Box Information for frame 247\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8249, 0.7949], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[597.4429, 449.7184, 711.3730, 736.9609],\n",
      "        [271.7147, 494.0753, 370.1125, 773.9927]], dtype=torch.float64)\n",
      "video 1/1 (248/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 68.9ms\n",
      "Bounding Box Information for frame 248\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8582, 0.7197], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[626.9546, 440.1440, 724.7194, 719.3652],\n",
      "        [312.5629, 494.2614, 418.4291, 763.3555]], dtype=torch.float64)\n",
      "video 1/1 (249/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 72.5ms\n",
      "Bounding Box Information for frame 249\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7831, 0.7462], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[653.6177, 435.4976, 772.1804, 707.4493],\n",
      "        [346.1911, 481.3988, 435.3094, 741.6724]], dtype=torch.float64)\n",
      "video 1/1 (250/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 79.5ms\n",
      "Bounding Box Information for frame 250\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8341, 0.7802], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[683.6555, 424.1620, 774.6017, 680.5737],\n",
      "        [380.9548, 471.5583, 474.5719, 729.4686]], dtype=torch.float64)\n",
      "video 1/1 (251/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 77.9ms\n",
      "Bounding Box Information for frame 251\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8354, 0.7378], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[711.2963, 427.3807, 805.6854, 679.2072],\n",
      "        [413.2243, 462.8458, 508.1275, 713.4830]], dtype=torch.float64)\n",
      "video 1/1 (252/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 80.1ms\n",
      "Bounding Box Information for frame 252\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7789, 0.6944], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[735.4685, 403.0800, 834.5762, 656.8692],\n",
      "        [449.3869, 429.4795, 544.1392, 690.8447]], dtype=torch.float64)\n",
      "video 1/1 (253/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 69.9ms\n",
      "Bounding Box Information for frame 253\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8130, 0.5586], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[753.7997, 379.4215, 846.8868, 645.6912],\n",
      "        [477.4696, 435.4865, 566.4312, 683.1182]], dtype=torch.float64)\n",
      "video 1/1 (254/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 73.9ms\n",
      "Bounding Box Information for frame 254\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5266, 0.7578, 0.5621], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1279.2711,  313.4094, 1302.1036,  373.2223],\n",
      "        [ 770.0259,  405.1641,  857.8147,  630.6231],\n",
      "        [ 489.9935,  390.8923,  588.0006,  670.9290]], dtype=torch.float64)\n",
      "video 1/1 (255/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 72.7ms\n",
      "Bounding Box Information for frame 255\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8171, 0.7455], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[794.0004, 407.0535, 874.1724, 616.2850],\n",
      "        [533.3201, 438.9585, 612.4696, 651.1419]], dtype=torch.float64)\n",
      "video 1/1 (256/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 72.4ms\n",
      "Bounding Box Information for frame 256\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5032, 0.8186, 0.8095], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1279.3198,  314.8100, 1300.3839,  375.7397],\n",
      "        [ 814.2497,  403.7851,  901.9019,  612.8055],\n",
      "        [ 556.1752,  437.7885,  638.0484,  647.0803]], dtype=torch.float64)\n",
      "video 1/1 (257/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 65.5ms\n",
      "Bounding Box Information for frame 257\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8187, 0.7276], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[825.3615, 396.2260, 898.4147, 598.6928],\n",
      "        [577.0909, 424.8830, 654.3829, 627.6655]], dtype=torch.float64)\n",
      "video 1/1 (258/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 78.3ms\n",
      "Bounding Box Information for frame 258\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8060, 0.7681], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[843.9005, 395.3972, 917.5366, 589.6718],\n",
      "        [605.3406, 424.9210, 678.0458, 617.6732]], dtype=torch.float64)\n",
      "video 1/1 (259/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 77.3ms\n",
      "Bounding Box Information for frame 259\n",
      "boxes_id = tensor([28., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7430, 0.8063, 0.7906], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[832.0087, 344.0946, 866.7336, 432.7327],\n",
      "        [862.6009, 389.4598, 942.9578, 583.0891],\n",
      "        [632.7477, 422.7958, 703.2784, 610.7157]], dtype=torch.float64)\n",
      "video 1/1 (260/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 69.9ms\n",
      "Bounding Box Information for frame 260\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5286, 0.8100, 0.7153], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1281.0377,  317.6292, 1305.2791,  381.7318],\n",
      "        [ 872.6851,  384.3617,  949.0338,  567.8835],\n",
      "        [ 653.2632,  412.2305,  714.9985,  598.5983]], dtype=torch.float64)\n",
      "video 1/1 (261/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 71.8ms\n",
      "Bounding Box Information for frame 261\n",
      "boxes_id = tensor([28., 26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6528, 0.5566, 0.7921, 0.7707], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 851.3628,  334.4540,  883.3213,  419.0142],\n",
      "        [1281.2817,  320.1776, 1306.5104,  381.3878],\n",
      "        [ 884.4382,  382.0026,  960.5087,  560.8739],\n",
      "        [ 674.6699,  411.2510,  743.8278,  595.5791]], dtype=torch.float64)\n",
      "video 1/1 (262/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 64.4ms\n",
      "Bounding Box Information for frame 262\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5499, 0.8334, 0.7776], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1280.4393,  322.3240, 1305.9811,  382.1755],\n",
      "        [ 908.3973,  376.9948,  979.2309,  547.8723],\n",
      "        [ 697.7560,  408.7418,  767.3852,  583.0329]], dtype=torch.float64)\n",
      "video 1/1 (263/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 75.9ms\n",
      "Bounding Box Information for frame 263\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6019, 0.8390, 0.8063], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1280.0211,  321.9873, 1304.1266,  380.9211],\n",
      "        [ 917.6481,  376.3477,  993.3903,  546.7795],\n",
      "        [ 712.1567,  402.6899,  777.8123,  574.1802]], dtype=torch.float64)\n",
      "video 1/1 (264/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 71.7ms\n",
      "Bounding Box Information for frame 264\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7832, 0.7930], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[930.5757, 372.8309, 995.5300, 540.7837],\n",
      "        [727.7665, 400.0209, 791.7805, 568.9765]], dtype=torch.float64)\n",
      "video 1/1 (265/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 78.3ms\n",
      "Bounding Box Information for frame 265\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5329, 0.7832, 0.7890], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1276.4756,  318.9305, 1301.3047,  384.2251],\n",
      "        [ 944.7437,  374.2111, 1002.8273,  533.4594],\n",
      "        [ 744.4315,  391.2664,  803.5701,  558.0218]], dtype=torch.float64)\n",
      "video 1/1 (266/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 70.5ms\n",
      "Bounding Box Information for frame 266\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5384, 0.8085, 0.7483], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1275.6934,  316.2472, 1298.6610,  384.8983],\n",
      "        [ 955.3989,  371.8375, 1018.9764,  527.3248],\n",
      "        [ 751.4994,  394.8354,  810.7462,  558.9624]], dtype=torch.float64)\n",
      "video 1/1 (267/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 66.6ms\n",
      "Bounding Box Information for frame 267\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5175, 0.7862, 0.7989], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1274.7791,  316.8767, 1298.2983,  387.1544],\n",
      "        [ 962.9023,  369.8257, 1022.2539,  523.7178],\n",
      "        [ 760.8056,  390.6924,  819.5021,  546.4586]], dtype=torch.float64)\n",
      "video 1/1 (268/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 68.1ms\n",
      "Bounding Box Information for frame 268\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5597, 0.7724, 0.8050], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1272.2817,  317.1574, 1298.3962,  387.0068],\n",
      "        [ 971.2830,  370.8694, 1026.6134,  518.6190],\n",
      "        [ 775.8038,  386.4826,  828.6649,  539.6791]], dtype=torch.float64)\n",
      "video 1/1 (269/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 69.6ms\n",
      "Bounding Box Information for frame 269\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5364, 0.7951, 0.8437], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1269.8549,  316.0838, 1293.3927,  388.6130],\n",
      "        [ 980.5327,  369.2563, 1040.0974,  511.4611],\n",
      "        [ 785.0008,  385.1244,  842.9738,  534.3608]], dtype=torch.float64)\n",
      "video 1/1 (270/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 76.2ms\n",
      "Bounding Box Information for frame 270\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5424, 0.7735, 0.7996], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1268.5328,  327.9468, 1291.0299,  388.7706],\n",
      "        [ 990.8460,  370.0341, 1045.2195,  510.1581],\n",
      "        [ 791.3157,  383.8164,  845.0110,  526.5799]], dtype=torch.float64)\n",
      "video 1/1 (271/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 70.4ms\n",
      "Bounding Box Information for frame 271\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5124, 0.7282, 0.7514], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1264.6974,  325.2397, 1288.3053,  394.2811],\n",
      "        [ 995.7162,  373.2684, 1047.6570,  500.5400],\n",
      "        [ 807.6394,  380.5890,  862.6139,  520.1514]], dtype=torch.float64)\n",
      "video 1/1 (272/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 95.9ms\n",
      "Bounding Box Information for frame 272\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8038, 0.7229], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1002.3002,  355.6878, 1060.0001,  501.4051],\n",
      "        [ 823.1010,  379.4713,  868.2881,  516.7506]], dtype=torch.float64)\n",
      "video 1/1 (273/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 71.4ms\n",
      "Bounding Box Information for frame 273\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7633, 0.7799], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1016.3102,  360.8323, 1068.4454,  493.4267],\n",
      "        [ 834.7020,  376.0631,  883.9138,  505.8413]], dtype=torch.float64)\n",
      "video 1/1 (274/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 76.1ms\n",
      "Bounding Box Information for frame 274\n",
      "boxes_id = tensor([29., 26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5746, 0.5224, 0.7854, 0.6903], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 481.2103,  365.7133,  528.0562,  508.5816],\n",
      "        [1258.8392,  322.9209, 1286.6603,  397.7348],\n",
      "        [1019.6202,  350.8692, 1075.9464,  487.7612],\n",
      "        [ 850.5306,  374.8936,  894.8736,  505.8976]], dtype=torch.float64)\n",
      "video 1/1 (275/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 96.7ms\n",
      "Bounding Box Information for frame 275\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7402, 0.8299], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1031.3087,  352.9041, 1080.1045,  487.7465],\n",
      "        [ 859.7587,  362.4339,  908.2795,  500.6574]], dtype=torch.float64)\n",
      "video 1/1 (276/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 90.9ms\n",
      "Bounding Box Information for frame 276\n",
      "boxes_id = tensor([24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7555, 0.8114], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1037.9219,  344.6470, 1094.7847,  480.4530],\n",
      "        [ 869.1004,  367.9624,  918.1910,  500.0320]], dtype=torch.float64)\n",
      "video 1/1 (277/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 84.4ms\n",
      "Bounding Box Information for frame 277\n",
      "boxes_id = tensor([30., 26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6609, 0.5497, 0.7609, 0.8073], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1171.5226,  306.5509, 1197.6962,  379.3284],\n",
      "        [1256.9769,  323.0250, 1284.8278,  405.2974],\n",
      "        [1045.6062,  338.2040, 1097.9724,  476.4403],\n",
      "        [ 880.0065,  362.7255,  926.8383,  494.9915]], dtype=torch.float64)\n",
      "video 1/1 (278/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 72.1ms\n",
      "Bounding Box Information for frame 278\n",
      "boxes_id = tensor([30., 26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5467, 0.5095, 0.7412, 0.7952], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1171.2616,  309.1049, 1194.7386,  382.7112],\n",
      "        [1257.0708,  324.8888, 1283.7931,  405.4063],\n",
      "        [1051.2268,  342.7304, 1101.6520,  472.7885],\n",
      "        [ 891.8760,  362.7606,  937.7252,  489.3771]], dtype=torch.float64)\n",
      "video 1/1 (279/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 76.1ms\n",
      "Bounding Box Information for frame 279\n",
      "boxes_id = tensor([30., 26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5715, 0.5376, 0.7356, 0.5420], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1169.1439,  308.9602, 1193.4460,  381.6639],\n",
      "        [1256.1683,  325.6707, 1283.7294,  408.4464],\n",
      "        [1058.7583,  347.9443, 1105.5249,  466.5062],\n",
      "        [ 898.6089,  367.4026,  942.6689,  489.1889]], dtype=torch.float64)\n",
      "video 1/1 (280/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 79.0ms\n",
      "Bounding Box Information for frame 280\n",
      "boxes_id = tensor([30., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6551, 0.7135, 0.7491], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1169.7372,  307.5880, 1193.4069,  382.5661],\n",
      "        [1064.2427,  345.6036, 1107.5110,  465.9427],\n",
      "        [ 909.3358,  364.6727,  950.5924,  477.6178]], dtype=torch.float64)\n",
      "video 1/1 (281/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 74.5ms\n",
      "Bounding Box Information for frame 281\n",
      "boxes_id = tensor([30., 26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6554, 0.6256, 0.7729, 0.7439], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1168.3828,  308.0361, 1192.8376,  383.8199],\n",
      "        [1255.0638,  328.3297, 1283.8069,  411.7307],\n",
      "        [1065.1985,  342.2120, 1110.3204,  460.6447],\n",
      "        [ 922.0296,  361.0265,  961.4899,  476.9092]], dtype=torch.float64)\n",
      "video 1/1 (282/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 86.3ms\n",
      "Bounding Box Information for frame 282\n",
      "boxes_id = tensor([30., 26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6221, 0.6002, 0.7681, 0.6168], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1169.3451,  308.0190, 1192.8629,  384.3856],\n",
      "        [1255.8242,  327.0117, 1283.6434,  412.6348],\n",
      "        [1068.6139,  341.7084, 1112.5470,  460.0573],\n",
      "        [ 928.1100,  361.2948,  969.8665,  472.8062]], dtype=torch.float64)\n",
      "video 1/1 (283/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 76.6ms\n",
      "Bounding Box Information for frame 283\n",
      "boxes_id = tensor([30., 26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5343, 0.6541, 0.7779, 0.5367], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1168.0948,  310.0925, 1193.2958,  385.2307],\n",
      "        [1254.5596,  325.9860, 1283.3939,  414.8952],\n",
      "        [1072.9231,  337.8907, 1122.3813,  456.4314],\n",
      "        [ 940.4240,  360.1494,  979.1951,  468.6352]], dtype=torch.float64)\n",
      "video 1/1 (284/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 76.8ms\n",
      "Bounding Box Information for frame 284\n",
      "boxes_id = tensor([30., 26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5468, 0.6071, 0.7419, 0.5934], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1168.1257,  305.6626, 1194.0963,  387.7611],\n",
      "        [1255.0911,  331.6560, 1283.2692,  414.9822],\n",
      "        [1078.2720,  341.3215, 1124.8774,  451.8270],\n",
      "        [ 952.4705,  354.0548,  991.6102,  469.5030]], dtype=torch.float64)\n",
      "video 1/1 (285/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 76.7ms\n",
      "Bounding Box Information for frame 285\n",
      "boxes_id = tensor([26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5904, 0.7279], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1253.7983,  331.3872, 1282.8279,  422.5127],\n",
      "        [1083.0508,  341.6511, 1128.7969,  450.5374]], dtype=torch.float64)\n",
      "video 1/1 (286/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 70.2ms\n",
      "Bounding Box Information for frame 286\n",
      "boxes_id = tensor([26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5939, 0.7558], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1253.4115,  332.3394, 1282.3553,  420.3509],\n",
      "        [1090.4624,  341.8374, 1139.6914,  449.5671]], dtype=torch.float64)\n",
      "video 1/1 (287/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 93.5ms\n",
      "Bounding Box Information for frame 287\n",
      "boxes_id = tensor([26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7696, 0.6609], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1249.3218,  329.9461, 1279.2775,  423.1369],\n",
      "        [1099.9561,  344.7008, 1142.2648,  446.5537]], dtype=torch.float64)\n",
      "video 1/1 (288/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 75.2ms\n",
      "Bounding Box Information for frame 288\n",
      "boxes_id = tensor([26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7562, 0.5913], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1250.7184,  333.6161, 1280.5107,  427.6296],\n",
      "        [1103.9823,  340.9900, 1147.4183,  442.4638]], dtype=torch.float64)\n",
      "video 1/1 (289/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 69.1ms\n",
      "Bounding Box Information for frame 289\n",
      "boxes_id = tensor([33., 26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8267, 0.7590, 0.6686], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 619.9472,  397.5360,  657.7149,  508.1991],\n",
      "        [1250.7220,  332.3567, 1282.2607,  428.9605],\n",
      "        [1111.4708,  339.7679, 1147.2423,  442.2873]], dtype=torch.float64)\n",
      "video 1/1 (290/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 79.5ms\n",
      "Bounding Box Information for frame 290\n",
      "boxes_id = tensor([33., 26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6903, 0.8026, 0.5759], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 623.1708,  395.3691,  670.5270,  511.7504],\n",
      "        [1249.7722,  332.3452, 1281.6240,  436.1732],\n",
      "        [1115.5499,  336.7966, 1155.8057,  436.8009]], dtype=torch.float64)\n",
      "video 1/1 (291/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 82.8ms\n",
      "Bounding Box Information for frame 291\n",
      "boxes_id = tensor([33., 26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6657, 0.7634, 0.5797], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 636.0439,  393.1048,  681.1520,  514.6445],\n",
      "        [1248.1461,  334.0435, 1280.7603,  438.4865],\n",
      "        [1118.9773,  336.4522, 1161.6808,  436.5739]], dtype=torch.float64)\n",
      "video 1/1 (292/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 84.7ms\n",
      "Bounding Box Information for frame 292\n",
      "boxes_id = tensor([33., 26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7427, 0.7650, 0.5491], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 642.0676,  392.7263,  690.9639,  514.5359],\n",
      "        [1247.5385,  337.6120, 1279.2378,  437.9036],\n",
      "        [1123.1786,  336.3554, 1161.9266,  434.1783]], dtype=torch.float64)\n",
      "video 1/1 (293/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 73.0ms\n",
      "Bounding Box Information for frame 293\n",
      "boxes_id = tensor([33., 26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7104, 0.8199, 0.6379], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 639.2551,  395.3834,  685.3265,  519.4434],\n",
      "        [1243.5645,  339.9377, 1277.3749,  441.0083],\n",
      "        [1128.6520,  335.7623, 1165.8733,  432.9664]], dtype=torch.float64)\n",
      "video 1/1 (294/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 71.1ms\n",
      "Bounding Box Information for frame 294\n",
      "boxes_id = tensor([33., 26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5269, 0.7493, 0.6118], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 623.5285,  408.5262,  669.3567,  518.1308],\n",
      "        [1241.6405,  341.1541, 1275.5674,  443.0498],\n",
      "        [1128.8778,  333.5010, 1165.9941,  424.6133]], dtype=torch.float64)\n",
      "video 1/1 (295/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 72.6ms\n",
      "Bounding Box Information for frame 295\n",
      "boxes_id = tensor([33., 26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5747, 0.7272, 0.6727], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 615.7375,  413.9459,  653.8489,  530.0516],\n",
      "        [1239.2988,  341.7981, 1275.8269,  445.3883],\n",
      "        [1129.9515,  332.0027, 1169.5388,  422.3737]], dtype=torch.float64)\n",
      "video 1/1 (296/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 72.9ms\n",
      "Bounding Box Information for frame 296\n",
      "boxes_id = tensor([33., 26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5291, 0.8218, 0.7128], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 596.3602,  402.1687,  644.0817,  534.4464],\n",
      "        [1238.3593,  344.8530, 1274.1608,  451.6591],\n",
      "        [1132.7097,  331.7110, 1170.7321,  424.3939]], dtype=torch.float64)\n",
      "video 1/1 (297/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 97.5ms\n",
      "Bounding Box Information for frame 297\n",
      "boxes_id = tensor([32., 26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5102, 0.7997, 0.7066], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 569.5030,  407.5500,  619.0323,  540.9462],\n",
      "        [1233.9598,  336.7327, 1273.5135,  455.0227],\n",
      "        [1131.0787,  331.3928, 1172.6072,  420.6355]], dtype=torch.float64)\n",
      "video 1/1 (298/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 88.6ms\n",
      "Bounding Box Information for frame 298\n",
      "boxes_id = tensor([26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7886], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1236.4204,  346.4911, 1275.9485,  458.1314]], dtype=torch.float64)\n",
      "video 1/1 (299/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 92.4ms\n",
      "Bounding Box Information for frame 299\n",
      "boxes_id = tensor([26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8118], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1234.3240,  347.9451, 1274.9247,  458.7440]], dtype=torch.float64)\n",
      "video 1/1 (300/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.5ms\n",
      "Bounding Box Information for frame 300\n",
      "boxes_id = tensor([26., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8078, 0.5858], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1229.3859,  343.0954, 1272.0436,  470.2199],\n",
      "        [1115.3922,  323.0515, 1146.8541,  412.0594]], dtype=torch.float64)\n",
      "video 1/1 (301/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 77.3ms\n",
      "Bounding Box Information for frame 301\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8393, 0.6865, 0.6032], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1227.7863,  346.8727, 1272.2007,  474.3531],\n",
      "        [1150.8938,  333.9507, 1188.5981,  419.7026],\n",
      "        [1114.3641,  322.6721, 1143.9287,  415.0101]], dtype=torch.float64)\n",
      "video 1/1 (302/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 76.8ms\n",
      "Bounding Box Information for frame 302\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8060, 0.5778, 0.7331], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1223.3633,  347.1142, 1267.7821,  479.8488],\n",
      "        [1152.2673,  331.9484, 1191.0208,  418.8902],\n",
      "        [1112.7762,  322.0299, 1143.8192,  417.4278]], dtype=torch.float64)\n",
      "video 1/1 (303/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 105.0ms\n",
      "Bounding Box Information for frame 303\n",
      "boxes_id = tensor([26., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8089, 0.5891], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1216.2349,  348.6594, 1259.0588,  482.5775],\n",
      "        [1112.4166,  317.8031, 1142.7833,  418.1720]], dtype=torch.float64)\n",
      "video 1/1 (304/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 91.3ms\n",
      "Bounding Box Information for frame 304\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6929, 0.5500, 0.5934], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1209.9247,  355.3124, 1252.5168,  488.3811],\n",
      "        [1164.4442,  327.8288, 1196.9418,  412.5546],\n",
      "        [1112.7935,  319.7057, 1142.4000,  418.7004]], dtype=torch.float64)\n",
      "video 1/1 (305/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 78.4ms\n",
      "Bounding Box Information for frame 305\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8074, 0.6281, 0.5679], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1200.7593,  356.7083, 1247.3516,  493.9165],\n",
      "        [1162.9941,  331.0182, 1198.2277,  407.8489],\n",
      "        [1111.6371,  322.7293, 1143.3055,  418.9139]], dtype=torch.float64)\n",
      "video 1/1 (306/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 72.6ms\n",
      "Bounding Box Information for frame 306\n",
      "boxes_id = tensor([26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7968], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1191.1514,  355.6095, 1237.1588,  496.0149]], dtype=torch.float64)\n",
      "video 1/1 (307/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 69.3ms\n",
      "Bounding Box Information for frame 307\n",
      "boxes_id = tensor([26., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7638, 0.5231], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1181.2054,  352.3216, 1229.1271,  507.2708],\n",
      "        [1111.1211,  328.4716, 1142.7906,  422.2479]], dtype=torch.float64)\n",
      "video 1/1 (308/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 76.3ms\n",
      "Bounding Box Information for frame 308\n",
      "boxes_id = tensor([26., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8156, 0.5337], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1169.7539,  357.5701, 1223.5375,  506.7430],\n",
      "        [1105.6525,  327.8302, 1139.9218,  425.2775]], dtype=torch.float64)\n",
      "video 1/1 (309/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 80.0ms\n",
      "Bounding Box Information for frame 309\n",
      "boxes_id = tensor([26., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7576, 0.7438], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1158.7991,  350.1201, 1207.5359,  515.3854],\n",
      "        [1095.8228,  328.4001, 1134.9009,  428.4510]], dtype=torch.float64)\n",
      "video 1/1 (310/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 72.9ms\n",
      "Bounding Box Information for frame 310\n",
      "boxes_id = tensor([26., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7087, 0.7030], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1149.8708,  365.2111, 1203.1575,  528.5941],\n",
      "        [1098.8453,  327.8361, 1135.3481,  432.6829]], dtype=torch.float64)\n",
      "video 1/1 (311/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 72.3ms\n",
      "Bounding Box Information for frame 311\n",
      "boxes_id = tensor([26., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8243, 0.7671], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1134.2234,  369.4648, 1198.3118,  528.9394],\n",
      "        [1095.7820,  326.0430, 1132.2222,  433.9388]], dtype=torch.float64)\n",
      "video 1/1 (312/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 69.1ms\n",
      "Bounding Box Information for frame 312\n",
      "boxes_id = tensor([26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7588, 0.5980, 0.7980], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1126.3563,  369.3547, 1181.6879,  543.8979],\n",
      "        [1186.1840,  324.6807, 1215.5233,  404.4495],\n",
      "        [1089.4889,  330.2013, 1124.8927,  435.8968]], dtype=torch.float64)\n",
      "video 1/1 (313/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 79.6ms\n",
      "Bounding Box Information for frame 313\n",
      "boxes_id = tensor([38., 37., 26., 24., 23.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5654, 0.6547, 0.8120, 0.5339, 0.7366], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 816.8472,  358.3368,  847.1387,  444.7982],\n",
      "        [ 768.2308,  360.8269,  815.6434,  470.2657],\n",
      "        [1116.2788,  382.3994, 1172.7024,  558.9772],\n",
      "        [1187.5496,  332.9730, 1220.1393,  404.5599],\n",
      "        [1086.3466,  328.7265, 1127.9558,  443.5761]], dtype=torch.float64)\n",
      "video 1/1 (314/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 5 persons, 78.2ms\n",
      "Bounding Box Information for frame 314\n",
      "boxes_id = tensor([37., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6079, 0.7786], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 770.8667,  373.8230,  812.5525,  477.6937],\n",
      "        [1098.2836,  378.9182, 1161.7516,  562.1776]], dtype=torch.float64)\n",
      "video 1/1 (315/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 72.5ms\n",
      "Bounding Box Information for frame 315\n",
      "boxes_id = tensor([37., 26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7011, 0.8037, 0.5244], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 769.1444,  380.2760,  820.9321,  497.3346],\n",
      "        [1086.8159,  382.7008, 1148.5503,  575.2856],\n",
      "        [1192.3488,  324.0056, 1223.6609,  395.4281]], dtype=torch.float64)\n",
      "video 1/1 (316/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 77.6ms\n",
      "Bounding Box Information for frame 316\n",
      "boxes_id = tensor([37., 36., 26., 24.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7229, 0.5035, 0.7286, 0.5289], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 771.9681,  379.6334,  822.4396,  509.8183],\n",
      "        [1074.4315,  339.0662, 1110.9911,  409.6037],\n",
      "        [1070.3521,  384.6207, 1136.3207,  593.5098],\n",
      "        [1193.2424,  326.1931, 1226.9626,  395.5616]], dtype=torch.float64)\n",
      "video 1/1 (317/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 72.0ms\n",
      "Bounding Box Information for frame 317\n",
      "boxes_id = tensor([37., 36., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6997, 0.5518, 0.8098], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 771.5186,  385.0381,  828.7888,  526.3994],\n",
      "        [1071.3918,  340.9269, 1106.5880,  407.3843],\n",
      "        [1058.1914,  384.3584, 1126.0704,  600.6625]], dtype=torch.float64)\n",
      "video 1/1 (318/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 76.2ms\n",
      "Bounding Box Information for frame 318\n",
      "boxes_id = tensor([37., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5547, 0.7880], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 767.8295,  390.1027,  832.3834,  555.9033],\n",
      "        [1034.7639,  403.4529, 1108.9586,  615.0286]], dtype=torch.float64)\n",
      "video 1/1 (319/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 77.4ms\n",
      "Bounding Box Information for frame 319\n",
      "boxes_id = tensor([39., 37., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6605, 0.5703, 0.8314], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 1., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 755.3350,  399.0779,  826.4929,  566.8723],\n",
      "        [ 761.0317,  471.3409,  821.6246,  583.4000],\n",
      "        [1012.2794,  404.6344, 1090.0167,  633.8846]], dtype=torch.float64)\n",
      "video 1/1 (320/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 1 bicycle, 73.7ms\n",
      "Bounding Box Information for frame 320\n",
      "boxes_id = tensor([39., 37., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5957, 0.5846, 0.8378], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 1., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 739.0385,  412.6400,  820.4927,  584.3876],\n",
      "        [ 756.4716,  496.3659,  807.6636,  622.4489],\n",
      "        [1001.4598,  409.9267, 1077.4867,  647.6091]], dtype=torch.float64)\n",
      "video 1/1 (321/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 1 bicycle, 81.6ms\n",
      "Bounding Box Information for frame 321\n",
      "boxes_id = tensor([39., 38., 37., 35., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7060, 0.5124, 0.6681, 0.6674, 0.8059], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 1., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 707.9039,  426.2832,  805.7818,  589.7090],\n",
      "        [ 822.9261,  362.2588,  859.6783,  455.5476],\n",
      "        [ 727.5775,  523.9382,  795.7181,  676.6796],\n",
      "        [1040.1486,  345.3691, 1079.3849,  467.3690],\n",
      "        [ 982.4105,  422.8904, 1064.1309,  673.0708]], dtype=torch.float64)\n",
      "video 1/1 (322/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 1 bicycle, 91.3ms\n",
      "Bounding Box Information for frame 322\n",
      "boxes_id = tensor([40., 39., 35., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5730, 0.8060, 0.7431, 0.7851], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 500.9871,  356.0171,  531.2954,  438.3024],\n",
      "        [ 688.2307,  450.7713,  799.8156,  688.5405],\n",
      "        [1026.7137,  350.4156, 1065.5596,  469.8186],\n",
      "        [ 955.3445,  429.8488, 1046.9987,  691.0242]], dtype=torch.float64)\n",
      "video 1/1 (323/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 90.9ms\n",
      "Bounding Box Information for frame 323\n",
      "boxes_id = tensor([41., 39., 35., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5817, 0.8434, 0.6118, 0.8456], dtype=torch.float64)\n",
      "boxes_cls = tensor([1., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 681.6929,  624.6469,  782.3705,  860.6376],\n",
      "        [ 657.5314,  486.6617,  792.6050,  769.6171],\n",
      "        [1021.4716,  351.6198, 1059.8116,  475.7532],\n",
      "        [ 935.5182,  427.6673, 1033.3719,  707.0648]], dtype=torch.float64)\n",
      "video 1/1 (324/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 1 bicycle, 86.2ms\n",
      "Bounding Box Information for frame 324\n",
      "boxes_id = tensor([38., 35., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6182, 0.7363, 0.8229], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 819.9485,  360.4821,  858.5277,  459.9130],\n",
      "        [1013.5811,  347.1241, 1056.7679,  478.9416],\n",
      "        [ 909.0458,  445.9573, 1009.6967,  733.7869]], dtype=torch.float64)\n",
      "video 1/1 (325/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 74.3ms\n",
      "Bounding Box Information for frame 325\n",
      "boxes_id = tensor([38., 35., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6601, 0.7199, 0.8683], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 815.9963,  364.8180,  853.1609,  460.6585],\n",
      "        [1007.2947,  349.2943, 1050.5995,  481.5173],\n",
      "        [ 870.0031,  443.1964,  980.2370,  769.5762]], dtype=torch.float64)\n",
      "video 1/1 (326/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 75.7ms\n",
      "Bounding Box Information for frame 326\n",
      "boxes_id = tensor([38., 35., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5983, 0.6963, 0.8610], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 808.0905,  364.2462,  848.0485,  467.1570],\n",
      "        [1001.0914,  360.6130, 1040.2170,  489.1922],\n",
      "        [ 839.6054,  449.7211,  951.4730,  789.3987]], dtype=torch.float64)\n",
      "video 1/1 (327/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 66.6ms\n",
      "Bounding Box Information for frame 327\n",
      "boxes_id = tensor([35., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7116, 0.8384], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 993.0260,  357.3089, 1038.8027,  490.7790],\n",
      "        [ 800.8153,  476.0973,  927.9216,  843.8373]], dtype=torch.float64)\n",
      "video 1/1 (328/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 70.4ms\n",
      "Bounding Box Information for frame 328\n",
      "boxes_id = tensor([38., 35., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6641, 0.7762, 0.8642], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 791.7396,  357.9691,  837.1520,  472.1557],\n",
      "        [ 981.7839,  365.9973, 1029.1362,  495.5820],\n",
      "        [ 747.6096,  483.9564,  892.6489,  881.7852]], dtype=torch.float64)\n",
      "video 1/1 (329/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 74.9ms\n",
      "Bounding Box Information for frame 329\n",
      "boxes_id = tensor([38., 35., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7568, 0.7734, 0.8817], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 787.0076,  356.0446,  834.0544,  477.6382],\n",
      "        [ 972.5447,  364.9669, 1018.3976,  504.9379],\n",
      "        [ 710.4728,  500.1270,  845.8526,  910.2217]], dtype=torch.float64)\n",
      "video 1/1 (330/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 86.2ms\n",
      "Bounding Box Information for frame 330\n",
      "boxes_id = tensor([38., 35., 26.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6156, 0.7727, 0.8496], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 775.8774,  363.9105,  823.8682,  478.7103],\n",
      "        [ 961.8685,  362.4912, 1013.0611,  504.3907],\n",
      "        [ 656.8788,  536.5546,  815.5087,  992.3829]], dtype=torch.float64)\n",
      "video 1/1 (331/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 73.6ms\n",
      "Bounding Box Information for frame 331\n",
      "boxes_id = tensor([44., 42., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7371, 0.8509, 0.6805, 0.7586], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 518.9512,  367.9647,  551.9457,  465.0867],\n",
      "        [ 574.0144,  545.1998,  755.9426, 1043.0740],\n",
      "        [ 767.7828,  351.4172,  814.0631,  480.4969],\n",
      "        [ 950.5018,  371.7807, 1000.2241,  511.6999]], dtype=torch.float64)\n",
      "video 1/1 (332/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 95.1ms\n",
      "Bounding Box Information for frame 332\n",
      "boxes_id = tensor([44., 39., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6870, 0.8334, 0.6486, 0.7977], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 523.1205,  368.9883,  557.1502,  469.5421],\n",
      "        [ 512.9227,  581.1125,  689.0623, 1064.1388],\n",
      "        [ 759.8756,  371.1814,  809.0339,  487.6154],\n",
      "        [ 936.4686,  372.7599,  991.2610,  522.2340]], dtype=torch.float64)\n",
      "video 1/1 (333/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 85.4ms\n",
      "Bounding Box Information for frame 333\n",
      "boxes_id = tensor([44., 43., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7211, 0.8724, 0.6439, 0.8105], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 525.9976,  370.5987,  563.3293,  470.1356],\n",
      "        [ 433.8180,  637.6623,  600.0261, 1079.7301],\n",
      "        [ 742.9095,  375.6329,  798.3068,  489.5522],\n",
      "        [ 932.0548,  371.5330,  987.1809,  525.5771]], dtype=torch.float64)\n",
      "video 1/1 (334/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 112.1ms\n",
      "Bounding Box Information for frame 334\n",
      "boxes_id = tensor([44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5906, 0.6916, 0.7779], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[529.2574, 371.4833, 565.3383, 471.7999],\n",
      "        [745.9698, 383.9371, 788.7524, 497.5508],\n",
      "        [920.0284, 371.1873, 977.2269, 532.4263]], dtype=torch.float64)\n",
      "video 1/1 (335/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 177.9ms\n",
      "Bounding Box Information for frame 335\n",
      "boxes_id = tensor([38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7046, 0.7944], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[740.4244, 384.3971, 780.4043, 499.1668],\n",
      "        [910.7954, 371.1533, 971.1120, 537.2084]], dtype=torch.float64)\n",
      "video 1/1 (336/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 137.0ms\n",
      "Bounding Box Information for frame 336\n",
      "boxes_id = tensor([38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6663, 0.7605], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[727.5978, 385.1825, 769.6491, 502.0153],\n",
      "        [902.1046, 378.7474, 958.0496, 545.7248]], dtype=torch.float64)\n",
      "video 1/1 (337/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 140.4ms\n",
      "Bounding Box Information for frame 337\n",
      "boxes_id = tensor([44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5001, 0.7480, 0.7189], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[529.9827, 376.9302, 571.5053, 481.4276],\n",
      "        [714.4131, 385.6106, 755.8103, 504.6059],\n",
      "        [890.4807, 380.6316, 950.9361, 554.2866]], dtype=torch.float64)\n",
      "video 1/1 (338/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 79.8ms\n",
      "Bounding Box Information for frame 338\n",
      "boxes_id = tensor([44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5708, 0.7676, 0.7534], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[527.2951, 373.8163, 565.9422, 482.6873],\n",
      "        [702.1447, 383.1617, 743.5675, 508.3593],\n",
      "        [874.1124, 383.6049, 934.7452, 562.7797]], dtype=torch.float64)\n",
      "video 1/1 (339/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 77.3ms\n",
      "Bounding Box Information for frame 339\n",
      "boxes_id = tensor([50., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5447, 0.6432, 0.8339], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1320.3772,  336.1373, 1348.3176,  408.3970],\n",
      "        [ 688.7379,  391.5047,  733.5475,  513.1350],\n",
      "        [ 857.7786,  388.0058,  925.5797,  577.6049]], dtype=torch.float64)\n",
      "video 1/1 (340/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 86.1ms\n",
      "Bounding Box Information for frame 340\n",
      "boxes_id = tensor([50., 44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5433, 0.5970, 0.6314, 0.8418], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1319.0935,  337.6483, 1345.5867,  407.8483],\n",
      "        [ 526.1454,  382.1079,  562.8231,  498.0797],\n",
      "        [ 675.2189,  387.8757,  717.0947,  519.1429],\n",
      "        [ 849.9457,  385.7341,  917.3157,  580.4932]], dtype=torch.float64)\n",
      "video 1/1 (341/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 73.0ms\n",
      "Bounding Box Information for frame 341\n",
      "boxes_id = tensor([44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6141, 0.7333, 0.8193], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[520.1765, 386.4864, 562.3003, 499.6566],\n",
      "        [656.2333, 408.2446, 702.6097, 525.5811],\n",
      "        [838.7501, 393.6687, 905.3430, 589.5200]], dtype=torch.float64)\n",
      "video 1/1 (342/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 79.9ms\n",
      "Bounding Box Information for frame 342\n",
      "boxes_id = tensor([44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6640, 0.6145, 0.8087], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[515.5483, 388.7495, 558.0447, 505.8282],\n",
      "        [641.0460, 391.6694, 685.9161, 525.7846],\n",
      "        [825.5234, 399.3371, 903.0429, 606.6041]], dtype=torch.float64)\n",
      "video 1/1 (343/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 74.4ms\n",
      "Bounding Box Information for frame 343\n",
      "boxes_id = tensor([44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7585, 0.7421, 0.8041], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[511.8184, 386.1431, 556.2372, 507.4507],\n",
      "        [621.8204, 411.1014, 675.9112, 535.1948],\n",
      "        [816.7390, 396.3988, 887.4214, 611.2507]], dtype=torch.float64)\n",
      "video 1/1 (344/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 73.5ms\n",
      "Bounding Box Information for frame 344\n",
      "boxes_id = tensor([50., 44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5306, 0.7051, 0.6811, 0.7925], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1314.6508,  337.1386, 1339.9812,  418.3969],\n",
      "        [ 514.6882,  391.8759,  562.5355,  510.5359],\n",
      "        [ 603.9163,  400.6772,  653.7087,  538.0466],\n",
      "        [ 799.9678,  407.4014,  873.9494,  631.4182]], dtype=torch.float64)\n",
      "video 1/1 (345/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 85.5ms\n",
      "Bounding Box Information for frame 345\n",
      "boxes_id = tensor([50., 44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5580, 0.7290, 0.6838, 0.7805], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1310.1061,  335.6143, 1337.9347,  422.1780],\n",
      "        [ 519.6268,  392.0186,  568.6426,  516.5789],\n",
      "        [ 591.8925,  409.0789,  640.6628,  545.4219],\n",
      "        [ 775.2486,  407.5670,  857.9974,  647.7243]], dtype=torch.float64)\n",
      "video 1/1 (346/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 71.5ms\n",
      "Bounding Box Information for frame 346\n",
      "boxes_id = tensor([44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5764, 0.6390, 0.8250], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[524.9406, 404.9129, 566.1065, 514.3297],\n",
      "        [570.2249, 407.9476, 624.4141, 549.3996],\n",
      "        [762.6957, 411.3233, 845.0331, 657.2701]], dtype=torch.float64)\n",
      "video 1/1 (347/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 70.8ms\n",
      "Bounding Box Information for frame 347\n",
      "boxes_id = tensor([50., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5878, 0.6208, 0.7284], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1306.3748,  335.7053, 1336.2854,  426.8283],\n",
      "        [ 547.3813,  422.3765,  605.3558,  551.7136],\n",
      "        [ 742.5970,  420.6824,  824.1460,  676.7379]], dtype=torch.float64)\n",
      "video 1/1 (348/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 73.9ms\n",
      "Bounding Box Information for frame 348\n",
      "boxes_id = tensor([50., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5167, 0.6756, 0.8386], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1303.7484,  333.7305, 1333.3573,  425.9506],\n",
      "        [ 529.7444,  401.9518,  592.1166,  554.3945],\n",
      "        [ 711.0300,  423.6942,  804.5515,  680.6147]], dtype=torch.float64)\n",
      "video 1/1 (349/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 88.6ms\n",
      "Bounding Box Information for frame 349\n",
      "boxes_id = tensor([50., 44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5161, 0.6533, 0.6609, 0.8227], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1296.7827,  336.2535, 1328.9097,  428.3153],\n",
      "        [ 511.3091,  421.2633,  551.8398,  560.5648],\n",
      "        [ 543.3488,  402.0992,  589.9858,  531.3408],\n",
      "        [ 685.3865,  432.7986,  783.6786,  704.3964]], dtype=torch.float64)\n",
      "video 1/1 (350/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 64.0ms\n",
      "Bounding Box Information for frame 350\n",
      "boxes_id = tensor([50., 44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6985, 0.6730, 0.7046, 0.7973], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1291.6963,  336.0444, 1324.0822,  433.9939],\n",
      "        [ 479.0125,  422.8608,  547.7798,  565.6194],\n",
      "        [ 549.8698,  401.2162,  600.2679,  528.1592],\n",
      "        [ 649.1083,  442.8576,  748.0375,  729.2194]], dtype=torch.float64)\n",
      "video 1/1 (351/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 76.4ms\n",
      "Bounding Box Information for frame 351\n",
      "boxes_id = tensor([50., 44., 38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6356, 0.6292, 0.7076, 0.8411], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1287.6134,  334.5886, 1322.0553,  436.3328],\n",
      "        [ 458.4212,  423.7845,  526.6816,  567.9351],\n",
      "        [ 556.5751,  399.1194,  605.5983,  533.3523],\n",
      "        [ 612.2459,  443.8782,  706.7715,  739.2204]], dtype=torch.float64)\n",
      "video 1/1 (352/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 79.7ms\n",
      "Bounding Box Information for frame 352\n",
      "boxes_id = tensor([35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8402], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[563.1202, 454.6820, 679.6381, 777.4109]], dtype=torch.float64)\n",
      "video 1/1 (353/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 80.2ms\n",
      "Bounding Box Information for frame 353\n",
      "boxes_id = tensor([38., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7092, 0.7757], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[559.4945, 392.8023, 612.2924, 524.4301],\n",
      "        [507.3079, 467.7879, 622.4607, 788.1675]], dtype=torch.float64)\n",
      "video 1/1 (354/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 89.9ms\n",
      "Bounding Box Information for frame 354\n",
      "boxes_id = tensor([50., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6782, 0.7718], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1273.9482,  340.9279, 1308.3909,  445.5192],\n",
      "        [ 454.7226,  479.7243,  582.7045,  816.0598]], dtype=torch.float64)\n",
      "video 1/1 (355/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 78.2ms\n",
      "Bounding Box Information for frame 355\n",
      "boxes_id = tensor([50., 35.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7265, 0.8441], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1266.5985,  341.7289, 1306.1288,  448.6862],\n",
      "        [ 381.2331,  499.1600,  521.4613,  852.5079]], dtype=torch.float64)\n",
      "video 1/1 (356/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 77.1ms\n",
      "Bounding Box Information for frame 356\n",
      "boxes_id = tensor([58., 50., 49., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8283, 0.7423, 0.6027, 0.7244], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 325.1318,  509.0670,  423.9079,  859.5040],\n",
      "        [1266.6510,  345.3749, 1305.4270,  449.4470],\n",
      "        [ 642.6307,  415.7042,  713.9371,  561.7211],\n",
      "        [ 555.6388,  403.5483,  610.7951,  554.8683]], dtype=torch.float64)\n",
      "video 1/1 (357/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 82.8ms\n",
      "Bounding Box Information for frame 357\n",
      "boxes_id = tensor([58., 50., 49., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7846, 0.6168, 0.7644, 0.7687], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 253.9611,  530.6512,  406.2974,  899.9440],\n",
      "        [1269.5035,  343.7883, 1310.3657,  453.6949],\n",
      "        [ 679.2570,  393.1868,  743.0966,  564.7791],\n",
      "        [ 551.2083,  404.0710,  610.4261,  561.7667]], dtype=torch.float64)\n",
      "video 1/1 (358/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 68.8ms\n",
      "Bounding Box Information for frame 358\n",
      "boxes_id = tensor([56., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8546, 0.7502, 0.8265], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 170.5871,  547.3370,  316.1447,  945.3215],\n",
      "        [1268.7162,  343.7175, 1310.4954,  453.4609],\n",
      "        [ 548.9739,  406.5404,  610.0174,  566.4293]], dtype=torch.float64)\n",
      "video 1/1 (359/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 89.0ms\n",
      "Bounding Box Information for frame 359\n",
      "boxes_id = tensor([61., 54., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8313, 0.8586, 0.7355, 0.8134], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 736.1529,  382.6194,  794.9292,  521.3388],\n",
      "        [  97.0481,  564.3899,  227.4521,  961.5704],\n",
      "        [1269.6189,  345.9363, 1313.7524,  457.3957],\n",
      "        [ 544.3535,  415.7157,  604.3358,  574.9374]], dtype=torch.float64)\n",
      "video 1/1 (360/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 75.9ms\n",
      "Bounding Box Information for frame 360\n",
      "boxes_id = tensor([61., 54., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7855, 0.8498, 0.7126, 0.7864], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 758.5009,  376.6685,  810.6268,  511.1700],\n",
      "        [  10.9984,  594.8622,  201.1485,  997.7203],\n",
      "        [1271.8766,  344.0907, 1312.5945,  458.7997],\n",
      "        [ 542.2770,  418.6684,  603.6979,  581.4874]], dtype=torch.float64)\n",
      "video 1/1 (361/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 72.1ms\n",
      "Bounding Box Information for frame 361\n",
      "boxes_id = tensor([61., 53., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7385, 0.5639, 0.6895, 0.7923], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[7.7844e+02, 3.7022e+02, 8.2306e+02, 4.9095e+02],\n",
      "        [1.9350e-01, 6.7507e+02, 8.7977e+01, 1.0306e+03],\n",
      "        [1.2696e+03, 3.4478e+02, 1.3132e+03, 4.6066e+02],\n",
      "        [5.4375e+02, 4.2041e+02, 6.1021e+02, 5.8468e+02]], dtype=torch.float64)\n",
      "video 1/1 (362/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 78.3ms\n",
      "Bounding Box Information for frame 362\n",
      "boxes_id = tensor([61., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6096, 0.5480, 0.7323], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 792.9798,  366.2651,  834.5079,  483.2325],\n",
      "        [1269.4343,  352.7138, 1312.7355,  471.3941],\n",
      "        [ 543.2833,  418.2318,  605.1317,  594.8035]], dtype=torch.float64)\n",
      "video 1/1 (363/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 75.3ms\n",
      "Bounding Box Information for frame 363\n",
      "boxes_id = tensor([50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5714, 0.8121], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1271.5497,  346.9162, 1313.3838,  471.4443],\n",
      "        [ 545.2079,  417.8629,  616.7617,  598.1961]], dtype=torch.float64)\n",
      "video 1/1 (364/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 79.2ms\n",
      "Bounding Box Information for frame 364\n",
      "boxes_id = tensor([50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6268, 0.8136], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1268.2657,  351.8089, 1311.7020,  476.6223],\n",
      "        [ 551.6805,  418.7831,  623.3057,  603.4750]], dtype=torch.float64)\n",
      "video 1/1 (365/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 77.8ms\n",
      "Bounding Box Information for frame 365\n",
      "boxes_id = tensor([50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6274, 0.7510], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1266.3394,  351.4253, 1309.2889,  484.7414],\n",
      "        [ 551.4365,  421.1009,  625.5029,  612.7028]], dtype=torch.float64)\n",
      "video 1/1 (366/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 76.0ms\n",
      "Bounding Box Information for frame 366\n",
      "boxes_id = tensor([50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6172, 0.8649], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1261.1923,  352.3771, 1305.0548,  483.1893],\n",
      "        [ 547.7955,  419.9674,  623.5082,  615.8234]], dtype=torch.float64)\n",
      "video 1/1 (367/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 77.7ms\n",
      "Bounding Box Information for frame 367\n",
      "boxes_id = tensor([50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7401, 0.8466], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1255.0892,  357.7921, 1298.7555,  489.1525],\n",
      "        [ 541.2056,  426.3367,  622.5543,  634.1316]], dtype=torch.float64)\n",
      "video 1/1 (368/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 74.5ms\n",
      "Bounding Box Information for frame 368\n",
      "boxes_id = tensor([38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8114], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[535.2313, 429.2794, 619.7158, 641.7983]], dtype=torch.float64)\n",
      "video 1/1 (369/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 81.1ms\n",
      "Bounding Box Information for frame 369\n",
      "boxes_id = tensor([38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8054], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[521.1342, 432.9102, 604.1986, 649.1375]], dtype=torch.float64)\n",
      "video 1/1 (370/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 80.0ms\n",
      "Bounding Box Information for frame 370\n",
      "boxes_id = tensor([50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7936, 0.7661], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1239.8309,  359.5475, 1290.4166,  507.3130],\n",
      "        [ 504.5979,  436.5388,  592.6550,  663.6290]], dtype=torch.float64)\n",
      "video 1/1 (371/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 79.0ms\n",
      "Bounding Box Information for frame 371\n",
      "boxes_id = tensor([50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8471, 0.7776], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1229.3365,  356.6577, 1288.7762,  511.0824],\n",
      "        [ 484.3510,  442.6469,  570.5050,  671.1702]], dtype=torch.float64)\n",
      "video 1/1 (372/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 73.8ms\n",
      "Bounding Box Information for frame 372\n",
      "boxes_id = tensor([50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7492, 0.7837], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1227.1045,  358.6852, 1287.3949,  512.6941],\n",
      "        [ 464.5994,  453.9185,  551.1158,  682.4341]], dtype=torch.float64)\n",
      "video 1/1 (373/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 85.8ms\n",
      "Bounding Box Information for frame 373\n",
      "boxes_id = tensor([64., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5209, 0.8343, 0.8286], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 881.8984,  343.9931,  910.2329,  420.9510],\n",
      "        [1229.2687,  363.4985, 1284.3628,  524.3661],\n",
      "        [ 437.8220,  455.4281,  531.6594,  705.3381]], dtype=torch.float64)\n",
      "video 1/1 (374/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 75.3ms\n",
      "Bounding Box Information for frame 374\n",
      "boxes_id = tensor([50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8382, 0.7449], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1219.7291,  363.0623, 1276.2626,  526.7241],\n",
      "        [ 421.9217,  460.5655,  507.3474,  711.5386]], dtype=torch.float64)\n",
      "video 1/1 (375/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 76.5ms\n",
      "Bounding Box Information for frame 375\n",
      "boxes_id = tensor([50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7852, 0.6105], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1221.8773,  369.9941, 1276.0513,  541.3511],\n",
      "        [ 394.2466,  467.3557,  493.5268,  730.9471]], dtype=torch.float64)\n",
      "video 1/1 (376/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 77.8ms\n",
      "Bounding Box Information for frame 376\n",
      "boxes_id = tensor([50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8346, 0.7372], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1213.1913,  369.8857, 1273.8486,  547.7122],\n",
      "        [ 363.6572,  475.1978,  445.3125,  741.4391]], dtype=torch.float64)\n",
      "video 1/1 (377/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 78.9ms\n",
      "Bounding Box Information for frame 377\n",
      "boxes_id = tensor([64., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5425, 0.8488, 0.7069], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 864.6931,  345.9759,  892.5776,  432.1722],\n",
      "        [1204.9158,  372.2793, 1268.6511,  549.8385],\n",
      "        [ 331.6452,  490.2662,  423.0402,  760.0009]], dtype=torch.float64)\n",
      "video 1/1 (378/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 82.7ms\n",
      "Bounding Box Information for frame 378\n",
      "boxes_id = tensor([64., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5375, 0.8246, 0.7521], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 859.5152,  343.6268,  894.0822,  437.0838],\n",
      "        [1198.1903,  377.3239, 1268.9558,  557.7845],\n",
      "        [ 278.9537,  494.0237,  392.0539,  774.8286]], dtype=torch.float64)\n",
      "video 1/1 (379/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 69.0ms\n",
      "Bounding Box Information for frame 379\n",
      "boxes_id = tensor([64., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5775, 0.8242, 0.7783], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 858.5094,  341.0832,  893.4611,  441.9578],\n",
      "        [1201.1569,  375.7823, 1266.3500,  568.1132],\n",
      "        [ 243.0782,  506.9308,  354.0472,  795.4915]], dtype=torch.float64)\n",
      "video 1/1 (380/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 74.4ms\n",
      "Bounding Box Information for frame 380\n",
      "boxes_id = tensor([64., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5755, 0.8083, 0.8352], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 858.5901,  352.8458,  890.4701,  444.3365],\n",
      "        [1198.4078,  379.2409, 1268.3091,  574.2181],\n",
      "        [ 213.3101,  516.0406,  328.2278,  812.0517]], dtype=torch.float64)\n",
      "video 1/1 (381/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 86.0ms\n",
      "Bounding Box Information for frame 381\n",
      "boxes_id = tensor([64., 54., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5530, 0.8486, 0.8452, 0.8124], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[8.5498e+02, 3.5601e+02, 8.9148e+02, 4.4422e+02],\n",
      "        [9.2171e-02, 6.8945e+02, 1.4848e+02, 1.0800e+03],\n",
      "        [1.1892e+03, 3.8277e+02, 1.2671e+03, 5.8578e+02],\n",
      "        [1.6898e+02, 5.2302e+02, 2.8766e+02, 8.3592e+02]], dtype=torch.float64)\n",
      "video 1/1 (382/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 77.5ms\n",
      "Bounding Box Information for frame 382\n",
      "boxes_id = tensor([64., 54., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5975, 0.8627, 0.8577, 0.8530], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[8.5400e+02, 3.5389e+02, 8.8678e+02, 4.4455e+02],\n",
      "        [4.7459e-01, 6.4933e+02, 2.3013e+02, 1.0793e+03],\n",
      "        [1.1972e+03, 3.8221e+02, 1.2738e+03, 5.9508e+02],\n",
      "        [1.3726e+02, 5.3865e+02, 2.6122e+02, 8.6464e+02]], dtype=torch.float64)\n",
      "video 1/1 (383/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 78.8ms\n",
      "Bounding Box Information for frame 383\n",
      "boxes_id = tensor([64., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5112, 0.8339, 0.8375], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 853.6317,  346.8835,  884.9167,  451.6890],\n",
      "        [1197.9962,  390.0335, 1274.0391,  615.8033],\n",
      "        [  97.2136,  622.6081,  300.1885, 1077.3699]], dtype=torch.float64)\n",
      "video 1/1 (384/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 79.1ms\n",
      "Bounding Box Information for frame 384\n",
      "boxes_id = tensor([64., 50., 38.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5341, 0.8307, 0.8965], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 849.4492,  364.6615,  883.3915,  454.4069],\n",
      "        [1177.6086,  395.0617, 1280.3569,  622.9470],\n",
      "        [ 173.7963,  600.4102,  366.8666, 1047.4208]], dtype=torch.float64)\n",
      "video 1/1 (385/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 83.8ms\n",
      "Bounding Box Information for frame 385\n",
      "boxes_id = tensor([68., 64., 58., 50., 49.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8892, 0.5120, 0.8799, 0.8721, 0.6545], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[   3.4417,  584.3157,  152.6073,  940.4015],\n",
      "        [ 847.1303,  365.4698,  877.8382,  454.3852],\n",
      "        [ 238.7234,  570.3902,  401.1662,  974.6915],\n",
      "        [1176.1520,  396.2919, 1283.6177,  636.1423],\n",
      "        [ 667.6430,  377.6721,  714.4323,  491.7554]], dtype=torch.float64)\n",
      "video 1/1 (386/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 5 persons, 80.3ms\n",
      "Bounding Box Information for frame 386\n",
      "boxes_id = tensor([68., 64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7319, 0.5572, 0.7480, 0.8030], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[1.4643e-01, 6.4228e+02, 7.7391e+01, 9.7387e+02],\n",
      "        [8.4289e+02, 3.6635e+02, 8.7616e+02, 4.5786e+02],\n",
      "        [3.1096e+02, 5.5426e+02, 4.7020e+02, 9.5147e+02],\n",
      "        [1.1798e+03, 4.0562e+02, 1.2728e+03, 6.5380e+02]], dtype=torch.float64)\n",
      "video 1/1 (387/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 77.5ms\n",
      "Bounding Box Information for frame 387\n",
      "boxes_id = tensor([69., 64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6819, 0.6136, 0.8909, 0.8427], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 712.5086,  370.3589,  759.6520,  474.8625],\n",
      "        [ 833.5611,  363.1706,  870.3966,  458.2393],\n",
      "        [ 366.0590,  533.3401,  522.8041,  903.0079],\n",
      "        [1152.2362,  402.5468, 1249.9193,  668.8693]], dtype=torch.float64)\n",
      "video 1/1 (388/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 73.7ms\n",
      "Bounding Box Information for frame 388\n",
      "boxes_id = tensor([69., 64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7437, 0.6734, 0.8792, 0.8492], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 731.9836,  370.2507,  774.0984,  466.5473],\n",
      "        [ 834.3806,  372.2141,  864.2548,  460.6124],\n",
      "        [ 405.1357,  503.4540,  543.9391,  857.8914],\n",
      "        [1134.1842,  406.7736, 1241.7711,  682.6355]], dtype=torch.float64)\n",
      "video 1/1 (389/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 73.7ms\n",
      "Bounding Box Information for frame 389\n",
      "boxes_id = tensor([64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6310, 0.8403, 0.8036], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 826.1389,  371.3740,  858.7969,  465.9080],\n",
      "        [ 452.6642,  503.3969,  584.5776,  843.8171],\n",
      "        [1147.4448,  416.6845, 1235.5610,  705.5704]], dtype=torch.float64)\n",
      "video 1/1 (390/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 76.8ms\n",
      "Bounding Box Information for frame 390\n",
      "boxes_id = tensor([69., 64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5243, 0.7201, 0.8763, 0.8639], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 761.6677,  368.3154,  797.1649,  457.7341],\n",
      "        [ 816.6581,  372.7812,  853.1900,  468.5084],\n",
      "        [ 493.1006,  488.1389,  617.2718,  808.7106],\n",
      "        [1105.7893,  418.8223, 1216.6440,  714.4495]], dtype=torch.float64)\n",
      "video 1/1 (391/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 79.6ms\n",
      "Bounding Box Information for frame 391\n",
      "boxes_id = tensor([69., 64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5176, 0.5372, 0.8824, 0.8904], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 773.7861,  354.9060,  809.1738,  450.1199],\n",
      "        [ 809.3607,  379.2661,  844.9168,  475.7664],\n",
      "        [ 515.3051,  476.8726,  629.9050,  781.8390],\n",
      "        [1081.1521,  427.9679, 1200.7094,  748.1696]], dtype=torch.float64)\n",
      "video 1/1 (392/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 4 persons, 78.2ms\n",
      "Bounding Box Information for frame 392\n",
      "boxes_id = tensor([69., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6279, 0.8305, 0.8222], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 780.6583,  350.0541,  837.8952,  479.5867],\n",
      "        [ 535.4362,  468.3260,  634.1921,  764.9175],\n",
      "        [1076.8984,  440.2950, 1185.9260,  771.1111]], dtype=torch.float64)\n",
      "video 1/1 (393/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 80.6ms\n",
      "Bounding Box Information for frame 393\n",
      "boxes_id = tensor([64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6777, 0.8811, 0.8995], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 784.1902,  370.6192,  830.3181,  484.0455],\n",
      "        [ 544.3820,  457.7254,  646.9609,  735.1972],\n",
      "        [1045.5154,  444.1770, 1176.0630,  786.0299]], dtype=torch.float64)\n",
      "video 1/1 (394/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 77.9ms\n",
      "Bounding Box Information for frame 394\n",
      "boxes_id = tensor([64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6482, 0.8556, 0.8926], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 780.1968,  372.5641,  818.2498,  489.0019],\n",
      "        [ 545.7779,  453.5281,  639.3832,  721.2784],\n",
      "        [1021.1246,  466.1566, 1189.1389,  836.5558]], dtype=torch.float64)\n",
      "video 1/1 (395/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 87.6ms\n",
      "Bounding Box Information for frame 395\n",
      "boxes_id = tensor([64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7376, 0.8508, 0.8654], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 762.1335,  383.3125,  809.7697,  492.2378],\n",
      "        [ 548.9095,  448.9476,  633.0549,  702.4377],\n",
      "        [1028.8088,  480.0252, 1188.3456,  872.5706]], dtype=torch.float64)\n",
      "video 1/1 (396/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 80.8ms\n",
      "Bounding Box Information for frame 396\n",
      "boxes_id = tensor([64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7094, 0.8615, 0.8880], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 750.8644,  387.1068,  792.8752,  492.6617],\n",
      "        [ 556.3484,  441.4827,  642.7681,  684.1918],\n",
      "        [ 986.6647,  497.0075, 1167.8684,  894.0247]], dtype=torch.float64)\n",
      "video 1/1 (397/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 71.8ms\n",
      "Bounding Box Information for frame 397\n",
      "boxes_id = tensor([64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7300, 0.8330, 0.8963], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 734.2698,  391.5372,  782.7224,  499.5930],\n",
      "        [ 556.5293,  442.1568,  629.4684,  665.5504],\n",
      "        [ 935.0063,  521.4064, 1161.0140,  961.1477]], dtype=torch.float64)\n",
      "video 1/1 (398/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 85.7ms\n",
      "Bounding Box Information for frame 398\n",
      "boxes_id = tensor([64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7386, 0.8322, 0.8524], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 720.2170,  397.1027,  767.0128,  501.9955],\n",
      "        [ 561.8284,  434.0989,  638.2277,  660.2121],\n",
      "        [ 942.4045,  537.4673, 1136.9371, 1006.0746]], dtype=torch.float64)\n",
      "video 1/1 (399/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 76.9ms\n",
      "Bounding Box Information for frame 399\n",
      "boxes_id = tensor([64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8343, 0.8307, 0.8428], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 703.0778,  393.5488,  747.4527,  505.6967],\n",
      "        [ 572.2645,  424.8796,  644.0340,  641.9788],\n",
      "        [ 886.5297,  545.5463, 1062.6151, 1028.8041]], dtype=torch.float64)\n",
      "video 1/1 (400/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 81.6ms\n",
      "Bounding Box Information for frame 400\n",
      "boxes_id = tensor([64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7107, 0.8113, 0.9208], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 683.5862,  396.5237,  734.1096,  514.8353],\n",
      "        [ 577.2056,  428.0198,  641.0714,  640.0349],\n",
      "        [ 813.0402,  575.9048, 1024.5670, 1080.0000]], dtype=torch.float64)\n",
      "video 1/1 (401/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 75.7ms\n",
      "Bounding Box Information for frame 401\n",
      "boxes_id = tensor([64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6491, 0.8029, 0.8796], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 671.9204,  400.1937,  715.8289,  516.4114],\n",
      "        [ 576.4127,  423.1307,  653.7367,  617.7206],\n",
      "        [ 795.8903,  595.7767,  967.9570, 1080.0000]], dtype=torch.float64)\n",
      "video 1/1 (402/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 90.0ms\n",
      "Bounding Box Information for frame 402\n",
      "boxes_id = tensor([64., 58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6240, 0.8676, 0.8666], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 652.6815,  409.8729,  698.9002,  524.2038],\n",
      "        [ 588.5283,  421.7072,  654.6158,  606.1621],\n",
      "        [ 712.5425,  620.0396,  901.0521, 1074.6436]], dtype=torch.float64)\n",
      "video 1/1 (403/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 3 persons, 81.3ms\n",
      "Bounding Box Information for frame 403\n",
      "boxes_id = tensor([58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6492, 0.9021], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 591.4695,  422.9200,  654.7194,  598.5952],\n",
      "        [ 573.5120,  678.4451,  844.1359, 1076.1344]], dtype=torch.float64)\n",
      "video 1/1 (404/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 76.8ms\n",
      "Bounding Box Information for frame 404\n",
      "boxes_id = tensor([58., 50.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7004, 0.8681], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 592.2286,  405.9987,  667.3971,  588.2027],\n",
      "        [ 547.5204,  719.4637,  756.9855, 1079.4625]], dtype=torch.float64)\n",
      "video 1/1 (405/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 83.2ms\n",
      "Bounding Box Information for frame 405\n",
      "boxes_id = tensor([58.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7401], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[596.2753, 414.8534, 664.2497, 577.4498]], dtype=torch.float64)\n",
      "video 1/1 (406/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.6ms\n",
      "Bounding Box Information for frame 406\n",
      "boxes_id = tensor([58.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6601], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[608.5027, 410.8952, 661.6734, 572.3000]], dtype=torch.float64)\n",
      "video 1/1 (407/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 74.1ms\n",
      "Bounding Box Information for frame 407\n",
      "boxes_id = tensor([65., 58.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6880, 0.7096], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[554.9279, 421.5959, 606.6064, 548.3570],\n",
      "        [604.0257, 409.3282, 661.6176, 566.5629]], dtype=torch.float64)\n",
      "video 1/1 (408/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 76.5ms\n",
      "Bounding Box Information for frame 408\n",
      "boxes_id = tensor([58.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6946], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[602.3100, 405.2521, 655.0158, 552.7310]], dtype=torch.float64)\n",
      "video 1/1 (409/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 87.8ms\n",
      "Bounding Box Information for frame 409\n",
      "boxes_id = tensor([71., 58.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6777, 0.5774], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[489.0578, 433.8147, 555.4280, 566.2883],\n",
      "        [587.6588, 403.3442, 651.5500, 554.6585]], dtype=torch.float64)\n",
      "video 1/1 (410/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 73.7ms\n",
      "Bounding Box Information for frame 410\n",
      "boxes_id = tensor([71., 66.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6920, 0.6274], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[471.0704, 430.2502, 526.4863, 571.6888],\n",
      "        [570.4796, 397.4248, 622.1151, 545.0717]], dtype=torch.float64)\n",
      "video 1/1 (411/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 66.5ms\n",
      "Bounding Box Information for frame 411\n",
      "boxes_id = tensor([65.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7382], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[553.7894, 404.2011, 606.3538, 547.8205]], dtype=torch.float64)\n",
      "video 1/1 (412/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 73.8ms\n",
      "Bounding Box Information for frame 412\n",
      "boxes_id = tensor([65.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6320], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[539.9841, 398.4852, 587.5323, 534.7856]], dtype=torch.float64)\n",
      "video 1/1 (413/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 84.3ms\n",
      "Bounding Box Information for frame 413\n",
      "boxes_id = tensor([65.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7226], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[526.2990, 398.9653, 573.2603, 532.4393]], dtype=torch.float64)\n",
      "video 1/1 (414/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 70.4ms\n",
      "Bounding Box Information for frame 414\n",
      "boxes_id = tensor([65.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6746], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[515.2003, 400.3048, 566.6970, 529.5271]], dtype=torch.float64)\n",
      "video 1/1 (415/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.7ms\n",
      "Bounding Box Information for frame 415\n",
      "boxes_id = tensor([69., 65.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6514, 0.7043], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[772.5617, 355.6317, 815.1334, 463.9511],\n",
      "        [512.7792, 398.1655, 555.4334, 523.6271]], dtype=torch.float64)\n",
      "video 1/1 (416/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 78.3ms\n",
      "Bounding Box Information for frame 416\n",
      "boxes_id = tensor([65.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8121], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[503.8058, 397.4396, 548.4647, 521.5582]], dtype=torch.float64)\n",
      "video 1/1 (417/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 78.9ms\n",
      "Bounding Box Information for frame 417\n",
      "boxes_id = tensor([65.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7757], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[503.9201, 395.3930, 546.9731, 514.1830]], dtype=torch.float64)\n",
      "video 1/1 (418/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 81.1ms\n",
      "Bounding Box Information for frame 418\n",
      "boxes_id = tensor([65.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8220], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[503.5802, 394.7141, 543.6543, 508.6307]], dtype=torch.float64)\n",
      "video 1/1 (419/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.9ms\n",
      "Bounding Box Information for frame 419\n",
      "boxes_id = tensor([65.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6424], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[497.3009, 388.4515, 540.0289, 504.4380]], dtype=torch.float64)\n",
      "video 1/1 (420/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 69.9ms\n",
      "video 1/1 (421/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 85.6ms\n",
      "video 1/1 (422/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 80.9ms\n",
      "video 1/1 (423/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 74.0ms\n",
      "video 1/1 (424/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 76.0ms\n",
      "Bounding Box Information for frame 424\n",
      "boxes_id = tensor([65.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5476], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[490.4611, 374.0414, 525.6318, 480.4670]], dtype=torch.float64)\n",
      "video 1/1 (425/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 107.1ms\n",
      "video 1/1 (426/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 72.7ms\n",
      "video 1/1 (427/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 70.9ms\n",
      "video 1/1 (428/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 73.3ms\n",
      "video 1/1 (429/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 83.3ms\n",
      "video 1/1 (430/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 79.0ms\n",
      "Bounding Box Information for frame 430\n",
      "boxes_id = tensor([65.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5524], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[491.7473, 368.5587, 521.9856, 458.1588]], dtype=torch.float64)\n",
      "video 1/1 (431/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 82.4ms\n",
      "video 1/1 (432/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 134.8ms\n",
      "video 1/1 (433/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 122.4ms\n",
      "video 1/1 (434/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 94.8ms\n",
      "video 1/1 (435/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 155.1ms\n",
      "video 1/1 (436/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 87.2ms\n",
      "video 1/1 (437/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 94.3ms\n",
      "video 1/1 (438/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 78.1ms\n",
      "video 1/1 (439/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 77.1ms\n",
      "video 1/1 (440/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 78.9ms\n",
      "video 1/1 (441/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 93.6ms\n",
      "video 1/1 (442/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 82.7ms\n",
      "video 1/1 (443/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 92.6ms\n",
      "video 1/1 (444/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 92.3ms\n",
      "video 1/1 (445/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 91.8ms\n",
      "video 1/1 (446/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 83.8ms\n",
      "video 1/1 (447/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 90.3ms\n",
      "video 1/1 (448/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 89.1ms\n",
      "video 1/1 (449/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 93.1ms\n",
      "video 1/1 (450/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.1ms\n",
      "video 1/1 (451/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 80.1ms\n",
      "video 1/1 (452/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 107.6ms\n",
      "video 1/1 (453/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 92.9ms\n",
      "video 1/1 (454/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 87.5ms\n",
      "video 1/1 (455/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 80.9ms\n",
      "video 1/1 (456/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 116.5ms\n",
      "video 1/1 (457/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 131.9ms\n",
      "video 1/1 (458/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 91.5ms\n",
      "video 1/1 (459/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 85.1ms\n",
      "video 1/1 (460/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 83.6ms\n",
      "video 1/1 (461/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 151.9ms\n",
      "video 1/1 (462/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 83.7ms\n",
      "video 1/1 (463/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 91.0ms\n",
      "video 1/1 (464/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 87.5ms\n",
      "video 1/1 (465/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 95.3ms\n",
      "video 1/1 (466/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 90.3ms\n",
      "video 1/1 (467/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.2ms\n",
      "video 1/1 (468/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 81.1ms\n",
      "video 1/1 (469/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 93.7ms\n",
      "video 1/1 (470/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 96.1ms\n",
      "video 1/1 (471/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 85.2ms\n",
      "video 1/1 (472/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 77.9ms\n",
      "video 1/1 (473/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 94.8ms\n",
      "video 1/1 (474/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 85.0ms\n",
      "video 1/1 (475/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 82.3ms\n",
      "video 1/1 (476/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 97.9ms\n",
      "video 1/1 (477/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 94.5ms\n",
      "video 1/1 (478/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 93.9ms\n",
      "video 1/1 (479/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 85.7ms\n",
      "video 1/1 (480/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 95.5ms\n",
      "video 1/1 (481/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 94.5ms\n",
      "video 1/1 (482/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.2ms\n",
      "video 1/1 (483/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.4ms\n",
      "video 1/1 (484/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 82.6ms\n",
      "video 1/1 (485/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.5ms\n",
      "video 1/1 (486/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 85.2ms\n",
      "video 1/1 (487/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 105.4ms\n",
      "video 1/1 (488/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 85.6ms\n",
      "video 1/1 (489/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 83.8ms\n",
      "video 1/1 (490/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 100.0ms\n",
      "video 1/1 (491/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 143.7ms\n",
      "video 1/1 (492/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 85.5ms\n",
      "video 1/1 (493/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 81.3ms\n",
      "video 1/1 (494/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 89.1ms\n",
      "video 1/1 (495/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 89.6ms\n",
      "video 1/1 (496/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 84.7ms\n",
      "video 1/1 (497/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 146.7ms\n",
      "video 1/1 (498/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 92.4ms\n",
      "video 1/1 (499/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 92.6ms\n",
      "video 1/1 (500/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 78.1ms\n",
      "video 1/1 (501/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 92.9ms\n",
      "video 1/1 (502/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 92.3ms\n",
      "video 1/1 (503/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 91.2ms\n",
      "Bounding Box Information for frame 503\n",
      "boxes_id = tensor([73.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5897], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[853.4390, 333.3969, 886.6630, 417.8359]], dtype=torch.float64)\n",
      "video 1/1 (504/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 86.9ms\n",
      "Bounding Box Information for frame 504\n",
      "boxes_id = tensor([73.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5754], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[852.1254, 333.9989, 886.8375, 419.0688]], dtype=torch.float64)\n",
      "video 1/1 (505/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 176.4ms\n",
      "video 1/1 (506/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 137.1ms\n",
      "video 1/1 (507/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 143.0ms\n",
      "video 1/1 (508/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 91.7ms\n",
      "video 1/1 (509/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 82.5ms\n",
      "video 1/1 (510/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 81.4ms\n",
      "Bounding Box Information for frame 510\n",
      "boxes_id = tensor([69.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6699], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[786.6621, 360.5712, 824.7233, 466.5381]], dtype=torch.float64)\n",
      "video 1/1 (511/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 81.5ms\n",
      "video 1/1 (512/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 134.2ms\n",
      "Bounding Box Information for frame 512\n",
      "boxes_id = tensor([77.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5522], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[736.1584, 379.6377, 784.2351, 482.2244]], dtype=torch.float64)\n",
      "video 1/1 (513/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 119.3ms\n",
      "video 1/1 (514/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 137.8ms\n",
      "Bounding Box Information for frame 514\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8383], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 34.4198, 588.0080, 171.2241, 932.9282]], dtype=torch.float64)\n",
      "video 1/1 (515/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 96.5ms\n",
      "Bounding Box Information for frame 515\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8135], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[ 89.9520, 570.7293, 254.9614, 917.7264]], dtype=torch.float64)\n",
      "video 1/1 (516/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 106.1ms\n",
      "Bounding Box Information for frame 516\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8138], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[145.1028, 546.8120, 268.9984, 871.2957]], dtype=torch.float64)\n",
      "video 1/1 (517/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 115.2ms\n",
      "Bounding Box Information for frame 517\n",
      "boxes_id = tensor([79., 66.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8183, 0.7497], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 3.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[197.1865, 540.5792, 307.7726, 848.0800],\n",
      "        [512.3773, 399.4655, 612.2612, 553.1069]], dtype=torch.float64)\n",
      "video 1/1 (518/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 1 motorcycle, 121.7ms\n",
      "Bounding Box Information for frame 518\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8570], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[235.7905, 519.8939, 347.8668, 820.0340]], dtype=torch.float64)\n",
      "video 1/1 (519/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 121.2ms\n",
      "video 1/1 (520/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 111.0ms\n",
      "Bounding Box Information for frame 520\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7301], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[319.5666, 499.9704, 419.3453, 782.5063]], dtype=torch.float64)\n",
      "video 1/1 (521/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 115.5ms\n",
      "Bounding Box Information for frame 521\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7263], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[366.3435, 491.4044, 450.1049, 756.0547]], dtype=torch.float64)\n",
      "video 1/1 (522/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 82.9ms\n",
      "Bounding Box Information for frame 522\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7236], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[402.3885, 489.0303, 513.8145, 744.9951]], dtype=torch.float64)\n",
      "video 1/1 (523/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 78.6ms\n",
      "Bounding Box Information for frame 523\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7921], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[442.0820, 467.0887, 521.1299, 716.8865]], dtype=torch.float64)\n",
      "video 1/1 (524/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 73.1ms\n",
      "Bounding Box Information for frame 524\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7655], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[470.2815, 466.2305, 545.2308, 708.9542]], dtype=torch.float64)\n",
      "video 1/1 (525/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 81.0ms\n",
      "Bounding Box Information for frame 525\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7671], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[488.3419, 453.4260, 583.1647, 686.8386]], dtype=torch.float64)\n",
      "video 1/1 (526/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 66.1ms\n",
      "Bounding Box Information for frame 526\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7706], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[516.9778, 447.1567, 594.1617, 669.2679]], dtype=torch.float64)\n",
      "video 1/1 (527/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 82.8ms\n",
      "Bounding Box Information for frame 527\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8255], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[535.6912, 445.4317, 602.6251, 665.2921]], dtype=torch.float64)\n",
      "video 1/1 (528/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 78.5ms\n",
      "Bounding Box Information for frame 528\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7564], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[545.7538, 437.5466, 614.1444, 638.2859]], dtype=torch.float64)\n",
      "video 1/1 (529/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.5ms\n",
      "Bounding Box Information for frame 529\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8123], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[559.2700, 436.0529, 629.1047, 629.8904]], dtype=torch.float64)\n",
      "video 1/1 (530/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 76.7ms\n",
      "Bounding Box Information for frame 530\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8350], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[572.5955, 426.8372, 638.3104, 620.4683]], dtype=torch.float64)\n",
      "video 1/1 (531/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 77.9ms\n",
      "Bounding Box Information for frame 531\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8458], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[576.3149, 424.6938, 640.3586, 614.6115]], dtype=torch.float64)\n",
      "video 1/1 (532/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 91.0ms\n",
      "Bounding Box Information for frame 532\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8080], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[582.0716, 419.3860, 646.6769, 598.4519]], dtype=torch.float64)\n",
      "video 1/1 (533/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 74.2ms\n",
      "Bounding Box Information for frame 533\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7951], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[586.0328, 416.1537, 648.9113, 587.7405]], dtype=torch.float64)\n",
      "video 1/1 (534/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 69.7ms\n",
      "Bounding Box Information for frame 534\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7567], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[585.9698, 417.8983, 647.3831, 584.5880]], dtype=torch.float64)\n",
      "video 1/1 (535/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 78.0ms\n",
      "Bounding Box Information for frame 535\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7931], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[581.0165, 414.0395, 643.6674, 577.4827]], dtype=torch.float64)\n",
      "video 1/1 (536/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 74.7ms\n",
      "Bounding Box Information for frame 536\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7850], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[581.0604, 416.3964, 641.4091, 575.4114]], dtype=torch.float64)\n",
      "video 1/1 (537/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 89.0ms\n",
      "Bounding Box Information for frame 537\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7545], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[579.5655, 409.7553, 635.7805, 560.7894]], dtype=torch.float64)\n",
      "video 1/1 (538/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.0ms\n",
      "Bounding Box Information for frame 538\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7479], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[573.7675, 413.5009, 624.6443, 554.7347]], dtype=torch.float64)\n",
      "video 1/1 (539/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 81.4ms\n",
      "Bounding Box Information for frame 539\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7208], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[564.0273, 414.6845, 618.0799, 552.6306]], dtype=torch.float64)\n",
      "video 1/1 (540/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 77.3ms\n",
      "Bounding Box Information for frame 540\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6906], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[557.7581, 405.4102, 608.3258, 548.9810]], dtype=torch.float64)\n",
      "video 1/1 (541/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 78.7ms\n",
      "Bounding Box Information for frame 541\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7223], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[547.9880, 408.3292, 597.5715, 546.5425]], dtype=torch.float64)\n",
      "video 1/1 (542/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 79.2ms\n",
      "Bounding Box Information for frame 542\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6404], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[539.5824, 408.4698, 589.9386, 541.3907]], dtype=torch.float64)\n",
      "video 1/1 (543/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 74.1ms\n",
      "Bounding Box Information for frame 543\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6124], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[539.6459, 407.2948, 582.7968, 535.9771]], dtype=torch.float64)\n",
      "video 1/1 (544/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 78.5ms\n",
      "Bounding Box Information for frame 544\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6665], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[530.4468, 405.1414, 577.0603, 530.0497]], dtype=torch.float64)\n",
      "video 1/1 (545/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 83.9ms\n",
      "video 1/1 (546/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 74.3ms\n",
      "video 1/1 (547/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 72.1ms\n",
      "video 1/1 (548/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 80.9ms\n",
      "Bounding Box Information for frame 548\n",
      "boxes_id = tensor([81.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5003], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[507.9470, 407.6994, 549.4790, 516.6459]], dtype=torch.float64)\n",
      "video 1/1 (549/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 79.6ms\n",
      "Bounding Box Information for frame 549\n",
      "boxes_id = tensor([81.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5040], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[503.1031, 356.2946, 546.4993, 505.4886]], dtype=torch.float64)\n",
      "video 1/1 (550/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 148.0ms\n",
      "Bounding Box Information for frame 550\n",
      "boxes_id = tensor([81.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6337], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[501.3589, 348.4422, 545.0140, 502.9634]], dtype=torch.float64)\n",
      "video 1/1 (551/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 179.7ms\n",
      "video 1/1 (552/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 (no detections), 116.5ms\n",
      "Bounding Box Information for frame 552\n",
      "boxes_id = tensor([81.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5574], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[496.9937, 355.4886, 545.1776, 495.0446]], dtype=torch.float64)\n",
      "video 1/1 (553/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 185.7ms\n",
      "Bounding Box Information for frame 553\n",
      "boxes_id = tensor([81.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6090], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[497.6563, 355.4980, 544.9785, 490.6498]], dtype=torch.float64)\n",
      "video 1/1 (554/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 103.6ms\n",
      "Bounding Box Information for frame 554\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5301], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[520.2689, 358.8711, 550.5751, 439.9912]], dtype=torch.float64)\n",
      "video 1/1 (555/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.7ms\n",
      "Bounding Box Information for frame 555\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5527], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[522.4223, 357.8645, 550.8007, 441.3617]], dtype=torch.float64)\n",
      "video 1/1 (556/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 90.8ms\n",
      "Bounding Box Information for frame 556\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5903], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[524.9427, 359.9372, 553.8128, 439.8081]], dtype=torch.float64)\n",
      "video 1/1 (557/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 73.5ms\n",
      "Bounding Box Information for frame 557\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6899], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[528.3885, 359.9259, 560.7832, 445.0191]], dtype=torch.float64)\n",
      "video 1/1 (558/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 72.2ms\n",
      "Bounding Box Information for frame 558\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6149, 0.7102], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[486.1452, 371.4781, 516.3311, 475.1064],\n",
      "        [533.7265, 362.9062, 561.8995, 450.2997]], dtype=torch.float64)\n",
      "video 1/1 (559/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 73.6ms\n",
      "Bounding Box Information for frame 559\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5185, 0.5971], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[484.2910, 371.7385, 516.4526, 465.7383],\n",
      "        [532.9184, 364.5081, 564.1392, 455.8985]], dtype=torch.float64)\n",
      "video 1/1 (560/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 83.1ms\n",
      "Bounding Box Information for frame 560\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5536, 0.5826], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[484.1270, 367.9001, 515.4357, 463.7558],\n",
      "        [534.4005, 369.2161, 564.9131, 458.9019]], dtype=torch.float64)\n",
      "video 1/1 (561/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 88.3ms\n",
      "Bounding Box Information for frame 561\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5542, 0.5205], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[485.5398, 367.0386, 515.4870, 457.1294],\n",
      "        [537.0454, 366.0478, 567.8792, 465.5698]], dtype=torch.float64)\n",
      "video 1/1 (562/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 77.2ms\n",
      "Bounding Box Information for frame 562\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6530, 0.6422], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[482.7043, 364.2625, 515.5422, 457.0259],\n",
      "        [535.8668, 372.0325, 569.0015, 468.5979]], dtype=torch.float64)\n",
      "video 1/1 (563/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 77.3ms\n",
      "Bounding Box Information for frame 563\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5962, 0.6787], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[481.9573, 365.0726, 514.8284, 452.0933],\n",
      "        [536.4053, 370.7402, 573.7017, 472.6615]], dtype=torch.float64)\n",
      "video 1/1 (564/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 75.2ms\n",
      "Bounding Box Information for frame 564\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5561, 0.6380], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[484.2399, 360.4778, 515.1160, 449.9777],\n",
      "        [543.1412, 372.3062, 578.7298, 471.7265]], dtype=torch.float64)\n",
      "video 1/1 (565/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 73.4ms\n",
      "Bounding Box Information for frame 565\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5308, 0.6851], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[486.9056, 361.8321, 515.0660, 445.4505],\n",
      "        [545.3562, 376.0257, 583.2325, 479.3971]], dtype=torch.float64)\n",
      "video 1/1 (566/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 81.4ms\n",
      "Bounding Box Information for frame 566\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6346], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[546.3979, 375.1716, 585.5627, 478.4648]], dtype=torch.float64)\n",
      "video 1/1 (567/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.2ms\n",
      "Bounding Box Information for frame 567\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5202, 0.6969], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[489.0419, 359.0894, 518.5944, 444.3272],\n",
      "        [554.2119, 378.9859, 591.8527, 481.0820]], dtype=torch.float64)\n",
      "video 1/1 (568/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 77.7ms\n",
      "Bounding Box Information for frame 568\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6945], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[555.7398, 383.0129, 594.5529, 488.3745]], dtype=torch.float64)\n",
      "video 1/1 (569/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 84.1ms\n",
      "Bounding Box Information for frame 569\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5068, 0.7106], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[490.8834, 355.1251, 520.0977, 436.5805],\n",
      "        [554.8173, 384.0629, 595.5557, 496.0226]], dtype=torch.float64)\n",
      "video 1/1 (570/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 84.8ms\n",
      "Bounding Box Information for frame 570\n",
      "boxes_id = tensor([81.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5379], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[495.2663, 357.1793, 521.5038, 433.9830]], dtype=torch.float64)\n",
      "video 1/1 (571/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.7ms\n",
      "Bounding Box Information for frame 571\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5595, 0.5987], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[498.4063, 356.3859, 526.0778, 430.9318],\n",
      "        [552.7202, 392.7208, 591.5485, 504.0106]], dtype=torch.float64)\n",
      "video 1/1 (572/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 80.1ms\n",
      "Bounding Box Information for frame 572\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7484], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[546.3953, 390.8311, 588.9287, 509.3450]], dtype=torch.float64)\n",
      "video 1/1 (573/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 79.6ms\n",
      "Bounding Box Information for frame 573\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6691], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[547.8677, 397.1462, 588.1493, 514.2910]], dtype=torch.float64)\n",
      "video 1/1 (574/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 71.5ms\n",
      "Bounding Box Information for frame 574\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6779], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[546.9151, 399.6857, 587.9582, 517.5844]], dtype=torch.float64)\n",
      "video 1/1 (575/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 81.9ms\n",
      "Bounding Box Information for frame 575\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7191], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[545.9299, 396.8079, 589.3105, 525.1481]], dtype=torch.float64)\n",
      "video 1/1 (576/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 78.5ms\n",
      "Bounding Box Information for frame 576\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.6177], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[548.4625, 401.5770, 594.2819, 527.2769]], dtype=torch.float64)\n",
      "video 1/1 (577/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 85.6ms\n",
      "Bounding Box Information for frame 577\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7816], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[553.4442, 400.5255, 599.6563, 529.9753]], dtype=torch.float64)\n",
      "video 1/1 (578/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 70.1ms\n",
      "Bounding Box Information for frame 578\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5462, 0.7332], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[506.0117, 364.3709, 530.3422, 431.1365],\n",
      "        [557.2202, 396.3177, 605.4762, 535.7234]], dtype=torch.float64)\n",
      "video 1/1 (579/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 89.6ms\n",
      "Bounding Box Information for frame 579\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7353], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[567.1945, 410.9287, 615.3018, 538.9261]], dtype=torch.float64)\n",
      "video 1/1 (580/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 75.2ms\n",
      "Bounding Box Information for frame 580\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5791, 0.7484], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[504.3752, 362.9759, 529.5515, 431.0826],\n",
      "        [578.5956, 396.2368, 628.8642, 543.5570]], dtype=torch.float64)\n",
      "video 1/1 (581/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 76.3ms\n",
      "Bounding Box Information for frame 581\n",
      "boxes_id = tensor([81., 79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.5705, 0.7753], dtype=torch.float64)\n",
      "boxes_cls = tensor([0., 0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[505.0952, 363.2242, 530.3242, 431.1891],\n",
      "        [585.7630, 402.6661, 635.7966, 550.6755]], dtype=torch.float64)\n",
      "video 1/1 (582/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 2 persons, 90.7ms\n",
      "Bounding Box Information for frame 582\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8345], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[593.6174, 408.0895, 648.3091, 551.4144]], dtype=torch.float64)\n",
      "video 1/1 (583/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 69.1ms\n",
      "Bounding Box Information for frame 583\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7673], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[604.9493, 406.6883, 655.1923, 556.7816]], dtype=torch.float64)\n",
      "video 1/1 (584/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 77.6ms\n",
      "Bounding Box Information for frame 584\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7754], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[608.3473, 417.0278, 659.1999, 566.0798]], dtype=torch.float64)\n",
      "video 1/1 (585/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 92.4ms\n",
      "Bounding Box Information for frame 585\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8435], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[613.5734, 412.9179, 672.0718, 567.7632]], dtype=torch.float64)\n",
      "video 1/1 (586/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 81.7ms\n",
      "Bounding Box Information for frame 586\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.8245], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[622.3243, 415.8672, 672.4034, 572.4780]], dtype=torch.float64)\n",
      "video 1/1 (587/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 82.8ms\n",
      "Bounding Box Information for frame 587\n",
      "boxes_id = tensor([79.], dtype=torch.float64)\n",
      "boxex_conf = tensor([0.7770], dtype=torch.float64)\n",
      "boxes_cls = tensor([0.], dtype=torch.float64)\n",
      "boxes_xyxy = tensor([[617.4580, 423.2652, 675.8262, 584.8913]], dtype=torch.float64)\n",
      "video 1/1 (588/617) /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/../footage/tampines_sample.mp4: 384x640 1 person, 80.3ms\n",
      "Speed: 2.1ms preprocess, 88.2ms inference, 0.7ms postprocess, 28.6ms tracking per image at shape (1, 3, 384, 640)\n",
      "MOT results saved to /Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/runs/track/exp11/mot/../footage/tampines_sample.mp4.txt\n"
     ]
    }
   ],
   "source": [
    "!python examples/track.py --yolo-model yolov8n --save-mot --source='../footage/tampines_sample.mp4' --vid_stride 5 # bboxes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae41376d-1af0-4cca-822c-7beb7b7930ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python examples/track.py --yolo-model yolov8n-pose --save-mot --show --source='../footage/tampines_sample.mp4' --vid_stride 5 # bboxes and pose keypoints only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d09ff-2149-40cc-b0ac-c7df8395432e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
