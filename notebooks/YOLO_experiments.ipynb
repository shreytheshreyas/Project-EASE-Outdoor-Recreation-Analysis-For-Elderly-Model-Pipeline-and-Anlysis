{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec58ca9-3394-4cee-845f-d3526f9b4777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torch \n",
    "import time \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b78e1d5-3e54-4d07-921f-a1d66fc7c2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking\n"
     ]
    }
   ],
   "source": [
    "%cd yolo_tracking/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d98d83-489d-4da3-b20f-8173873a4779",
   "metadata": {},
   "source": [
    "#### Necessary Functions for Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e04bc6e3-4957-4e1b-879f-de700a0f0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distinct_object(dataframe):\n",
    "    object_set = set()\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        object_set.add(row['object_id'])\n",
    "    return object_set\n",
    "\n",
    "def get_distinct_objects_by_class(dataframe):\n",
    "    object_set = set()\n",
    "    object_class_tracker = {}\n",
    "\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        if row['object_id'] in object_set:\n",
    "            continue\n",
    "        objet_set.add(row['object_id'])\n",
    "        object_class_tracker[row['object_class']] == 0 if row['object_class'] not in object_class_tracker else object_class_tracker[row['object_class']] + 1\n",
    "\n",
    "    return object_class_tracker\n",
    "        \n",
    "def distinct_object_counter(dataframe):\n",
    "    num_of_distinct_objects = get_distinct_object(dataframe)\n",
    "    return len(num_of_distinct_objects)\n",
    "\n",
    "def detection_counter(dataframe):\n",
    "    object_set = set()\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        object_set.add((row['frame_id'], row['object_id']))\n",
    "    return len(object_set)\n",
    "\n",
    "def file_processor(experiment_files):\n",
    "    number_of_distinct_objects = {}\n",
    "    number_of_detections = {}\n",
    "    for key, value in experiment_files.items():\n",
    "        dataframe = pd.read_csv(value)\n",
    "        number_of_distinct_objects[key] = distinct_object_counter(dataframe)\n",
    "        number_of_detections[key] = detection_counter(dataframe)\n",
    "    return (number_of_detections, number_of_distinct_objects)\n",
    "\n",
    "\n",
    "def data_plotter(time_complexities, number_of_detections, num_of_distinct_objects, Model_Type):\n",
    "    fig, (axs1, axs2, axs3) = plt.subplots(1, 3, figsize=(30,5))\n",
    "\n",
    "    fig.suptitle(f'{Model_Type} Statisitcs', fontsize=20)\n",
    "    \n",
    "    axs1.plot(time_complexities.keys(), time_complexities.values())\n",
    "    axs1.set_title('Time Complexity')\n",
    "    axs1.set_xlabel('Algoritm frame processing rate')\n",
    "    axs1.set_ylabel('Processing Time in seconds')\n",
    "    \n",
    "    axs2.bar(number_of_detections.keys(), number_of_detections.values())\n",
    "    axs2.set_title('Number of Detections made')\n",
    "    axs2.set_xlabel('Frame Processing Rate')\n",
    "    axs2.set_ylabel('Number of Objects Identified')\n",
    "    \n",
    "    axs3.bar(num_of_distinct_objects.keys(), num_of_distinct_objects.values())\n",
    "    axs3.set_title('Number of distinct objects identified')\n",
    "    axs3.set_xlabel('Frame Processing Rate')\n",
    "    axs3.set_ylabel('Number of Objects Identified')\n",
    "\n",
    "    \n",
    "def dataframe_concatenator(experiment_files, model_type):\n",
    "    result_dataframe = pd.read_csv(experiment_files['1fps'])\n",
    "    result_dataframe['model_type'] = model_type\n",
    "    result_dataframe['vid_stride'] = '1fps'\n",
    "    for key, value in experiment_files.items():\n",
    "        if key == '1fps':\n",
    "            continue\n",
    "        dataframe = pd.read_csv(value)\n",
    "        dataframe['model_type'] = 'yolov8s'\n",
    "        dataframe['vid_stride'] = key\n",
    "        result_dataframe = pd.concat([result_dataframe, dataframe], axis=0)\n",
    "        \n",
    "    result_dataframe\n",
    "    result_dataframe.to_csv(f'combined_result_{model_type}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5f8f4-72c2-454f-b260-9fb78ba4c792",
   "metadata": {},
   "source": [
    "## Experimentation with YOLOv8s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa375368-523b-40be-86d5-a2cbe7afdd30",
   "metadata": {},
   "source": [
    "The following set of experiments are being used to analyse the performance and accuracy of the BoxMot tracking algorithm for different variations of the video stride. Video stride in the context of object tracking refers to how many frames of the input video is being processed in 1 second, it is important you do not confuse this with the input video frame rate, because that frame rate refers to the rate at which the camera is taking snapshots of the scene to form the output video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af558e04-3ccf-4174-909d-0c1d7cd0ac07",
   "metadata": {},
   "source": [
    "Processing the output video at 1fps will give us the most accurate form of object detection, because you are tracking at such a slow rate that it gives the YOLO algorithm it give the algorithm more time to analyse a frame in one second. Object tracking algorithms can sometimes perform better on videos with lower frame rates, but the relationship between frame rate and tracking performance is not straightforward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa02257a-b6ac-4f52-b8c7-395941ff0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_s = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03c2ca-776e-4e34-911b-77fe8cffd1ad",
   "metadata": {},
   "source": [
    "### Processing Video output at 1 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974a10a3-dd5f-4ceb-a657-aa8139b3438b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-15 13:49:50.852\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mboxmot.utils.checks\u001b[0m:\u001b[36mcheck_packages\u001b[0m:\u001b[36m26\u001b[0m - \u001b[31m\u001b[1mThe 'ultralytics@ git+https://github.com/mikel-brostrom/ultralytics.git' distribution was not found and is required by the application\u001b[0m\n",
      "\u001b[32m2024-03-15 13:49:50.853\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mboxmot.utils.checks\u001b[0m:\u001b[36mcheck_packages\u001b[0m:\u001b[36m29\u001b[0m - \u001b[33m\u001b[1m\n",
      "Missing packages: \"ultralytics @ git+https://github.com/mikel-brostrom/ultralytics.git\" \n",
      "Atempting installation...\u001b[0m\n",
      "\u001b[32m2024-03-15 13:49:56.122\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mboxmot.utils.checks\u001b[0m:\u001b[36mcheck_packages\u001b[0m:\u001b[36m35\u001b[0m - \u001b[32m\u001b[1mAll the missing packages were installed successfully\u001b[0m\n",
      "yolov8s\n",
      "False\n",
      "Default Video Frame Rate: 1\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/examples/track.py\", line 213, in <module>\n",
      "    run(opt)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/shreyaskumar/Documents/Shreyas/Work/yolo_v_8_testing/yolo_tracking/examples/track.py\", line 105, in run\n",
      "    for frame_idx, r in enumerate(results):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 35, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ultralytics/engine/predictor.py\", line 240, in stream_inference\n",
      "    self.setup_source(source if source is not None else self.args.source)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ultralytics/engine/predictor.py\", line 215, in setup_source\n",
      "    self.dataset = load_inference_source(source=source,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ultralytics/data/build.py\", line 172, in load_inference_source\n",
      "    dataset = LoadImages(source, imgsz=imgsz, vid_stride=vid_stride)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ultralytics/data/loaders.py\", line 292, in __init__\n",
      "    raise FileNotFoundError(f'{p} does not exist')\n",
      "FileNotFoundError: ../footage/sample.mp4 does not exist\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "!python3 examples/track.py --yolo-model yolov8s --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 1 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcdc8185-8b66-450a-a45f-2a16461fcf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excution Time for baseline BoxMot Model: 12.445793867111206\n"
     ]
    }
   ],
   "source": [
    "time_complexities_model_s['1fps'] = end_time-start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {time_complexities_model_s[\"1fps\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc13bd1b-3bcc-447f-b147-2f46fde2a2a0",
   "metadata": {},
   "source": [
    "### Processing Video output at 5 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59377bc1-2408-4793-931f-855dc97e8403",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: python\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8s --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 5 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbc81096-ca8d-450d-bba6-7ed53abcc052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excution Time for baseline BoxMot Model: 0.1217198371887207\n"
     ]
    }
   ],
   "source": [
    "time_complexities_model_s['5fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {end_time-start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b259c18-cd7d-4e31-b6f7-bddea16a03e9",
   "metadata": {},
   "source": [
    "### Processing Video output at 10 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64dbd07a-0863-4e96-a3e1-787650500266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: python\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8s --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 10 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "408e2271-7e60-46cb-bd04-c4191e4b57d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excution Time for baseline BoxMot Model: 0.12117791175842285\n"
     ]
    }
   ],
   "source": [
    "time_complexities_model_s['10fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {end_time-start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f22ac-a793-4df1-98c6-1c643cc8feab",
   "metadata": {},
   "source": [
    "### Processing Video output at 15 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "005d31c3-de16-4782-ba8c-64413843c208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: python\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8s --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 15 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36cb6262-2403-496d-ba9b-c619aa87f519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excution Time for baseline BoxMot Model: 0.12293577194213867\n"
     ]
    }
   ],
   "source": [
    "time_complexities_model_s['15fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {end_time-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0085b37d-039e-4cb4-a2d9-7fcc4c1bfab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of yolov8s at their respective time complexites is as follows:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time_complexities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerformance of yolov8s at their respective time complexites is as follows:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtime_complexities\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time_complexities' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'Performance of yolov8s at their respective time complexites is as follows:')\n",
    "print(time_complexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c1721-5c52-49c2-afea-4ad040edb6ff",
   "metadata": {},
   "source": [
    "## Experimentation with YOLOv8m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828930df-a2ef-476e-9637-3e7e096ec7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_m = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c02a4-c2c8-447e-8466-761fa6357800",
   "metadata": {},
   "source": [
    "### Processing Video output at 1 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba68f03-30b7-415d-8cd7-127bf013e4f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8m --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 1 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2fede-f236-4f3e-862e-65a2fc97c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_m['1fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {end_time-start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d72f0-9b4d-47ee-9881-0a0867472773",
   "metadata": {},
   "source": [
    "### Processing Video output at 5 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90ddc5-6cf5-41e0-8cb8-bbc9a80a759c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8m --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 5 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6cf119-758f-4c96-8e97-04071b137963",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_m['5fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {time_complexities_model_m[\"5fps\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026cf50-cf77-429c-909d-efae8a654917",
   "metadata": {},
   "source": [
    "### Processing Video output at 10 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe612756-c4a4-4998-bd56-1b02f9711624",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8m --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 10 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb81ad-e111-4eb9-a752-04f4a795d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_m['10fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {time_complexities_model_m[\"10fps\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c728325-150a-4c50-9e0f-4dd2fe294b3e",
   "metadata": {},
   "source": [
    "### Processing Video output at 15 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd02776-073f-499e-a4d0-60009f4d2e57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8m --show --save-mot --source='../footage/sample.mp44' --save --vid_stride 15 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454dec0-4502-4896-9bf5-6eaff69ed7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_m['15fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {time_complexities_model_m[\"15fps\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48722b9-ff8c-48e1-bf5c-336e639bd08b",
   "metadata": {},
   "source": [
    "## Experimentation with YOLOv8l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed83624-3e5d-4007-a432-59e193d66e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_l = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ac2e92-11ea-461e-a0d9-8d83784dd946",
   "metadata": {},
   "source": [
    "### Processing Video output at 1 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be13db-78c2-41c9-8c10-9e9229df7c28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8l --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 1 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835f2c6-eada-4321-9a8f-e42e66d6f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_l['1fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {time_complexities_model_l[\"1fps\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225e986-ff80-443d-aeb9-ef4fd04f2557",
   "metadata": {},
   "source": [
    "### Processing Video output at 5 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f163124-b4aa-433e-980a-6d2a71aa5154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8l --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 5 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577f4f5-d626-4f49-b2ec-43836c4377e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_l['5fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {time_complexities_model_l[\"5fps\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29adcecf-12bd-48e9-8ef7-7820f29fa91f",
   "metadata": {},
   "source": [
    "### Processing Video output at 10 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d630179c-9626-4b55-b262-57f7261491da",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8l --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 10 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6b5a8-368f-46c0-8425-8989040e428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_l['10fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {time_complexities_model_l[\"10fps\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d20686-4b18-40d2-9195-72feda4588f1",
   "metadata": {},
   "source": [
    "### Processing Video output at 15 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f495902-500d-4213-8333-dc20d62d8cb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8l --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 15 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463eea36-1b17-4d08-8307-cede1660e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_l['15fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {time_complexities_model_l[\"15fps\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc0931a-51cd-426d-95f0-5f4783f19177",
   "metadata": {},
   "source": [
    "## Experimentation with YOLOv8X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1132c2-bf5c-43cd-9e7e-2698407a6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_x = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25327b53-2c57-4c3d-9478-637634b43fe9",
   "metadata": {},
   "source": [
    "### Processing Video output at 1 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4393f9d-2b5d-43db-bd7b-8d4380e943d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8x --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 1 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9258f-9fcf-411f-a2b0-89775bfbf998",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_x['1fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {time_complexities_model_x[\"1fps\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94a4e2-d1b7-49fe-b0d9-f27ce555f29e",
   "metadata": {},
   "source": [
    "### Processing Video output at 5 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b66a4-d5e0-4210-9e6f-d660463613ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8x --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 5 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da109692-5f07-4800-a982-64a895a1b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_x['5fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {time_complexities_model_x[\"5fps\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160fbd6d-043f-4b23-8ea1-54abff9a2604",
   "metadata": {},
   "source": [
    "### Processing Video output at 10 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e36ea8-2c63-45fd-af1b-3916782d7e66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8x --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 10 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc38ade-e659-4fad-9564-caa58e827cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_x['10fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {time_complexities_model_x[\"10fps\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ec54e-b3d7-45cc-8938-975a34857e32",
   "metadata": {},
   "source": [
    "### Processing Video output at 15 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a052c5-db07-4e9d-9448-be7e27ed6961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "!python examples/track.py --yolo-model yolov8x --show --save-mot --source='../footage/sample.mp4' --save --vid_stride 15 # bboxes only\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6173183-2161-4dd5-82aa-b82322bb8320",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_x['15fps'] = end_time - start_time\n",
    "print(f'Excution Time for baseline BoxMot Model: {time_complexities_model_x[\"15fps\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010e7a88-c747-4ab2-be8d-023a93e6d62f",
   "metadata": {},
   "source": [
    "## Visualising and Analysing the Model Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff84450-118e-4bf8-8cb0-f90ddee9d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_files_small = {\n",
    "    '1fps': './runs/track/yolov8s_experiment_vid_stride_1/mot/yolov8s_tampines_sample_2_vid_stride_args_1_post_processed_results.csv',\n",
    "    '5fps': './runs/track/yolov8s_experiment_vid_stride_5/mot/yolov8s_tampines_sample_2_vid_stride_args_5_post_processed_results.csv',\n",
    "    '10fps': './runs/track/yolov8s_experiment_vid_stride_10/mot/yolov8s_tampines_sample_2_vid_stride_args_10_post_processed_results.csv',\n",
    "    '15fps': './runs/track/yolov8s_experiment_vid_stride_15/mot/yolov8s_tampines_sample_2_vid_stride_args_15_post_processed_results.csv',\n",
    "}\n",
    "\n",
    "experiment_files_medium = {\n",
    "    '1fps': './runs/track/yolov8m_experiment_vid_stride_1/mot/yolov8m_tampines_sample_2_vid_stride_args_1_post_processed_results.csv',\n",
    "    '5fps': './runs/track/yolov8m_experiment_vid_stride_5/mot/yolov8m_tampines_sample_2_vid_stride_args_5_post_processed_results.csv',\n",
    "    '10fps': './runs/track/yolov8m_experiment_vid_stride_10/mot/yolov8m_tampines_sample_2_vid_stride_args_10_post_processed_results.csv',\n",
    "    '15fps': './runs/track/yolov8m_experiment_vid_stride_15/mot/yolov8m_tampines_sample_2_vid_stride_args_15_post_processed_results.csv',\n",
    "}\n",
    "\n",
    "experiment_files_large = {\n",
    "    '1fps': './runs/track/yolov8l_experiment_vid_stride_1/mot/yolov8l_tampines_sample_2_vid_stride_args_1_post_processed_results.csv',\n",
    "    '5fps': './runs/track/yolov8l_experiment_vid_stride_5/mot/yolov8l_tampines_sample_2_vid_stride_args_5_post_processed_results.csv',\n",
    "    '10fps': './runs/track/yolov8l_experiment_vid_stride_10/mot/yolov8l_tampines_sample_2_vid_stride_args_10_post_processed_results.csv',\n",
    "    '15fps': './runs/track/yolov8l_experiment_vid_stride_15/mot/yolov8l_tampines_sample_2_vid_stride_args_15_post_processed_results.csv',\n",
    "}\n",
    "\n",
    "experiment_files_extra_large = {\n",
    "    '1fps': './runs/track/yolov8x_experiment_vid_stride_1/mot/yolov8x_tampines_sample_2_vid_stride_args_1_post_processed_results.csv',\n",
    "    '5fps': './runs/track/yolov8x_experiment_vid_stride_5/mot/yolov8x_tampines_sample_2_vid_stride_args_5_post_processed_results.csv',\n",
    "    '10fps': './runs/track/yolov8x_experiment_vid_stride_10/mot/yolov8x_tampines_sample_2_vid_stride_args_10_post_processed_results.csv',\n",
    "    '15fps': './runs/track/yolov8x_experiment_vid_stride_15/mot/yolov8x_tampines_sample_2_vid_stride_args_15_post_processed_results.csv',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e23e5e-762c-46dc-9ea1-6ac5343667b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_detections_model_s, num_of_distinct_objects_model_s = file_processor(experiment_files_small)\n",
    "number_of_detections_model_m, num_of_distinct_objects_model_m = file_processor(experiment_files_medium)\n",
    "number_of_detections_model_l, num_of_distinct_objects_model_l = file_processor(experiment_files_large)\n",
    "number_of_detections_model_x, num_of_distinct_objects_model_x = file_processor(experiment_files_extra_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf306f3d-608a-46fa-b6ab-6acd897e2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plotter(time_complexities_model_s, number_of_detections_model_s, num_of_distinct_objects_model_s, 'YOLOv8s Model Statistics')\n",
    "data_plotter(time_complexities_model_m, number_of_detections_model_m, num_of_distinct_objects_model_m, 'YOLOv8m Model Statistics')\n",
    "data_plotter(time_complexities_model_l, number_of_detections_model_l, num_of_distinct_objects_model_l, 'YOLOv8l Model Statistics')\n",
    "data_plotter(time_complexities_model_x, number_of_detections_model_x, num_of_distinct_objects_model_x, 'YOLOv8x Model Statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1476a0ce-4f69-45b6-ade6-ffcd8ee760f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_concatenator(experiment_files_small, 'yolov8s')\n",
    "dataframe_concatenator(experiment_files_medium, 'yolov8m')\n",
    "dataframe_concatenator(experiment_files_large, 'yolov8l')\n",
    "dataframe_concatenator(experiment_files_extra_large, 'yolov8x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b80ef-65bc-4811-ae71-43127c8ec37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_complexities_model_m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
